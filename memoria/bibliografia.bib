@book{koza92,
		author    = "Koza, John R.",
		title     = "Genetic Programming: On the Programming of Computers by Means of Natural Selection",
		publisher = "MIT Press",
		year      = "1992"
}


@misc{ wiki:latex,
       author = "Wikipedia",
       title = "LaTeX --- Wikipedia{,} La enciclopedia libre",
       year = "2015",
       url = "https://es.wikipedia.org/w/index.php?title=LaTeX&oldid=84209252",
       note = "[Internet; descargado 30-septiembre-2015]"
}


@article{bortolot2005,
  title={Estimating forest biomass using small footprint LiDAR data: An individual tree-based approach that incorporates training data},
  author={Bortolot, Zachary J and Wynne, Randolph H},
  journal={ISPRS Journal of Photogrammetry and Remote Sensing},
  volume={59},
  number={6},
  pages={342--360},
  year={2005},
  publisher={Elsevier}
}

@article{malgheet_iris_2021,
	title = {Iris Recognition Development Techniques: A Comprehensive Review},
	volume = {2021},
	issn = {1099-0526, 1076-2787},
	url = {https://www.hindawi.com/journals/complexity/2021/6641247/},
	doi = {10.1155/2021/6641247},
	shorttitle = {Iris Recognition Development Techniques},
	abstract = {Recently, iris recognition techniques have achieved great performance in identification. Among authentication techniques, iris recognition systems have received attention very much due to their rich iris texture which gives robust standards for identifying individuals. Notwithstanding this, there are several challenges in unrestricted recognition environments. In this article, the researchers present the techniques used in different phases of the recognition system of the iris image. The researchers also reviewed the methods associated with each phase. The recognition system is divided into seven phases, namely, the acquisition phase in which the iris images are acquired, the preprocessing phase in which the quality of the iris image is improved, the segmentation phase in which the iris region is separated from the background of the image, the normalization phase in which the segmented iris region is shaped into a rectangle, the feature extraction phase in which the features of the iris region are extracted, the feature selection phase in which the unique features of the iris are selected using feature selection techniques, and finally the classification phase in which the iris images are classified. This article also explains the two approaches of iris recognition which are the traditional approach and the deep learning approach. In addition, the researchers discuss the advantages and disadvantages of previous techniques as well as the limitations and benefits of both the traditional and deep learning approaches of iris recognition. This study can be considered as an initial step towards a large-scale study about iris recognition.},
	pages = {1--32},
	journaltitle = {Complexity},
	shortjournal = {Complexity},
	author = {Malgheet, Jasem Rahman and Manshor, Noridayu Bt and Affendey, Lilly Suriani},
	editor = {Lopez Gutierrez, Rosa M.},
	urldate = {2022-05-31},
	date = {2021-08-23},
	langid = {english},
	file = {Malgheet et al. - 2021 - Iris Recognition Development Techniques A Compreh.pdf:C\:\\Users\\na-ch\\Zotero\\storage\\GENGASSS\\Malgheet et al. - 2021 - Iris Recognition Development Techniques A Compreh.pdf:application/pdf},
}

@article{tfg_iris_2020,
title = {Sistema Clasificador de iris},
author = {Arrobo Acaro, Johnson Bolívar },
date = {2020-09-28}
}

@article{boyd_post-mortem_2020,
	title = {Post-Mortem Iris Recognition—A Survey and Assessment of the State of the Art},
	volume = {8},
	issn = {2169-3536},
	url = {https://ieeexplore.ieee.org/document/9146139/},
	doi = {10.1109/ACCESS.2020.3011364},
	abstract = {Post-mortem biometrics entails utilizing the biometric data of a deceased individual for determining or verifying human identity. Due to fundamental biological changes that occur in a person’s biometric traits after death, post-mortem data can be signiﬁcantly different from ante-mortem data, introducing new challenges for biometric sensors, feature extractors and matchers. This paper surveys research to date on the problem of using iris images acquired after death for automated human recognition. A comprehensive review of existing literature is complemented by a summary of the most recent results and observations offered in these publications. This survey is unique in several elements. Firstly, it is the ﬁrst publication to consider iris recognition where gallery images are acquired before death (peri-mortem images) and the probe images are acquired after death from the same subjects. Secondly, results are presented from the largest database of peri-mortem and post-mortem iris images, collected from 213 subjects by two independent institutions located in the U.S. and Poland. Thirdly, post-mortem recognition viability is assessed using more than 20 iris recognition algorithms, ranging from the classic (e.g., Gabor ﬁltering-based) to the modern (e.g., deep learning-based). Finally, we provide a medically informed commentary on post-mortem iris, analyze the reasons for recognition failures, and identify key directions for future research.},
	pages = {136570--136593},
	journaltitle = {{IEEE} Access},
	shortjournal = {{IEEE} Access},
	author = {Boyd, Aidan and Yadav, Shivangi and Swearingen, Thomas and Kuehlkamp, Andrey and Trokielewicz, Mateusz and Benjamin, Eric and Maciejewicz, Piotr and Chute, Dennis and Ross, Arun and Flynn, Patrick and Bowyer, Kevin and Czajka, Adam},
	urldate = {2022-06-02},
	date = {2020},
	langid = {english},
	file = {Boyd et al. - 2020 - Post-Mortem Iris Recognition—A Survey and Assessme.pdf:C\:\\Users\\na-ch\\Zotero\\storage\\HT5ZXT4Q\\Boyd et al. - 2020 - Post-Mortem Iris Recognition—A Survey and Assessme.pdf:application/pdf},
}

@article{abdullah_iris_2015,
	title = {Iris Recognition Using Wavelet Transform and Artificial Neural Networks},
	abstract = {In this approach to get more accuracy of the iris recognition, is composed of many steps: capturing the iris image, determining the location of the iris boundaries, normalization, preprocessed using median filter to remove noise, using wavelet transform for two types of filter, Haar and Daubechies (db4), in order to extract the features and finally using the matching by artificial feed forward neural network with back propagation algorithm ({FFBNN}) for training and testing iris image. In this proposed system, two database systems are used. The first is {CASIA} database system (version 1.0) (Chinese Academy of Sciences Institute of Automation). And, the second is {REAL} database system by using real persons and each person takes many images for recognition through camera Mobile Type of Galaxy Note3. In {CASIA} System, the iris recognition rate for Haar filter was 84.2\% and for Daubechies filter was 92.8\%, while in Real system, the iris recognition rate for Haar filter was 90\% and for Daubechies filter was 98.7\%, this means the Daubechies filter was the best in time and error from the Haar filter. Finally, this system is efficient, because the performance measurement of {FAR} was 0\%. The results and the experiments were implemented by P4 computer and the software package {MATLAB} (R2011a).},
	pages = {13},
	author = {Abdullah, Dr Hadeel N},
	date = {2015},
	langid = {english},
	file = {Abdullah - 2015 - Iris Recognition Using Wavelet Transform and Artif.PDF:C\:\\Users\\na-ch\\Zotero\\storage\\6WJAGCHN\\Abdullah - 2015 - Iris Recognition Using Wavelet Transform and Artif.PDF:application/pdf},
}

@misc{minaee_deepiris_2019,
	title = {{DeepIris}: Iris Recognition Using A Deep Learning Approach},
	url = {http://arxiv.org/abs/1907.09380},
	shorttitle = {{DeepIris}},
	abstract = {Iris recognition has been an active research area during last few decades, because of its wide applications in security, from airports to homeland security border control. Different features and algorithms have been proposed for iris recognition in the past. In this paper, we propose an end-to-end deep learning framework for iris recognition based on residual convolutional neural network ({CNN}), which can jointly learn the feature representation and perform recognition. We train our model on a well-known iris recognition dataset using only a few training images from each class, and show promising results and improvements over previous approaches. We also present a visualization technique which is able to detect the important areas in iris images which can mostly impact the recognition results. We believe this framework can be widely used for other biometrics recognition tasks, helping to have a more scalable and accurate systems.},
	publisher = {{arXiv}},
	author = {Minaee, Shervin and Abdolrashidi, Amirali},
	urldate = {2022-06-02},
	date = {2019-07-22},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {1907.09380 [cs]},
	note = {Number: {arXiv}:1907.09380},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning},
	file = {Minaee and Abdolrashidi - 2019 - DeepIris Iris Recognition Using A Deep Learning A.pdf:C\:\\Users\\na-ch\\Zotero\\storage\\HKSE335Z\\Minaee and Abdolrashidi - 2019 - DeepIris Iris Recognition Using A Deep Learning A.pdf:application/pdf},
}

@misc{zeiler_visualizing_2013,
	title = {Visualizing and Understanding Convolutional Networks},
	url = {http://arxiv.org/abs/1311.2901},
	abstract = {Large Convolutional Network models have recently demonstrated impressive classiﬁcation performance on the {ImageNet} benchmark (Krizhevsky et al., 2012). However there is no clear understanding of why they perform so well, or how they might be improved. In this paper we address both issues. We introduce a novel visualization technique that gives insight into the function of intermediate feature layers and the operation of the classiﬁer. Used in a diagnostic role, these visualizations allow us to ﬁnd model architectures that outperform Krizhevsky et al. on the {ImageNet} classiﬁcation benchmark. We also perform an ablation study to discover the performance contribution from diﬀerent model layers. We show our {ImageNet} model generalizes well to other datasets: when the softmax classiﬁer is retrained, it convincingly beats the current state-of-the-art results on Caltech-101 and Caltech-256 datasets.},
	publisher = {{arXiv}},
	author = {Zeiler, Matthew D. and Fergus, Rob},
	urldate = {2022-06-02},
	date = {2013-11-28},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {1311.2901 [cs]},
	note = {Number: {arXiv}:1311.2901},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	file = {Zeiler and Fergus - 2013 - Visualizing and Understanding Convolutional Networ.pdf:C\:\\Users\\na-ch\\Zotero\\storage\\93QBRAJ9\\Zeiler and Fergus - 2013 - Visualizing and Understanding Convolutional Networ.pdf:application/pdf},
}



