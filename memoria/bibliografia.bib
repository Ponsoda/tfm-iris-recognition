@book{koza92,
  author    = {Koza, John R.},
  title     = {Genetic Programming: On the Programming of Computers by Means of Natural Selection},
  publisher = {MIT Press},
  year      = {1992}
}


@misc{wiki:latex,
  author = {Wikipedia},
  title  = {LaTeX --- Wikipedia{,} La enciclopedia libre},
  year   = {2015},
  url    = {https://es.wikipedia.org/w/index.php?title=LaTeX&oldid=84209252},
  note   = {[Internet; descargado 30-septiembre-2015]}
}


@article{bortolot2005,
  title     = {Estimating forest biomass using small footprint LiDAR data: An individual tree-based approach that incorporates training data},
  author    = {Bortolot, Zachary J and Wynne, Randolph H},
  journal   = {ISPRS Journal of Photogrammetry and Remote Sensing},
  volume    = {59},
  number    = {6},
  pages     = {342--360},
  year      = {2005},
  publisher = {Elsevier}
}

@article{malgheet_iris_2021,
  title        = {Iris Recognition Development Techniques: A Comprehensive Review},
  volume       = {2021},
  issn         = {1099-0526, 1076-2787},
  url          = {https://www.hindawi.com/journals/complexity/2021/6641247/},
  doi          = {10.1155/2021/6641247},
  shorttitle   = {Iris Recognition Development Techniques},
  abstract     = {Recently, iris recognition techniques have achieved great performance in identification. Among authentication techniques, iris recognition systems have received attention very much due to their rich iris texture which gives robust standards for identifying individuals. Notwithstanding this, there are several challenges in unrestricted recognition environments. In this article, the researchers present the techniques used in different phases of the recognition system of the iris image. The researchers also reviewed the methods associated with each phase. The recognition system is divided into seven phases, namely, the acquisition phase in which the iris images are acquired, the preprocessing phase in which the quality of the iris image is improved, the segmentation phase in which the iris region is separated from the background of the image, the normalization phase in which the segmented iris region is shaped into a rectangle, the feature extraction phase in which the features of the iris region are extracted, the feature selection phase in which the unique features of the iris are selected using feature selection techniques, and finally the classification phase in which the iris images are classified. This article also explains the two approaches of iris recognition which are the traditional approach and the deep learning approach. In addition, the researchers discuss the advantages and disadvantages of previous techniques as well as the limitations and benefits of both the traditional and deep learning approaches of iris recognition. This study can be considered as an initial step towards a large-scale study about iris recognition.},
  pages        = {1--32},
  journaltitle = {Complexity},
  shortjournal = {Complexity},
  author       = {Malgheet, Jasem Rahman and Manshor, Noridayu Bt and Affendey, Lilly Suriani},
  editor       = {Lopez Gutierrez, Rosa M.},
  urldate      = {2022-05-31},
  date         = {2021-08-23},
  langid       = {english},
  file         = {Malgheet et al. - 2021 - Iris Recognition Development Techniques A Compreh.pdf:C\:\\Users\\na-ch\\Zotero\\storage\\GENGASSS\\Malgheet et al. - 2021 - Iris Recognition Development Techniques A Compreh.pdf:application/pdf}
}

@article{tfg_iris_2020,
  title  = {Sistema Clasificador de iris},
  author = {Arrobo Acaro, Johnson Bolívar },
  date   = {2020-09-28}
}

@article{boyd_post-mortem_2020,
  title        = {Post-Mortem Iris Recognition—A Survey and Assessment of the State of the Art},
  volume       = {8},
  issn         = {2169-3536},
  url          = {https://ieeexplore.ieee.org/document/9146139/},
  doi          = {10.1109/ACCESS.2020.3011364},
  abstract     = {Post-mortem biometrics entails utilizing the biometric data of a deceased individual for determining or verifying human identity. Due to fundamental biological changes that occur in a person’s biometric traits after death, post-mortem data can be signiﬁcantly different from ante-mortem data, introducing new challenges for biometric sensors, feature extractors and matchers. This paper surveys research to date on the problem of using iris images acquired after death for automated human recognition. A comprehensive review of existing literature is complemented by a summary of the most recent results and observations offered in these publications. This survey is unique in several elements. Firstly, it is the ﬁrst publication to consider iris recognition where gallery images are acquired before death (peri-mortem images) and the probe images are acquired after death from the same subjects. Secondly, results are presented from the largest database of peri-mortem and post-mortem iris images, collected from 213 subjects by two independent institutions located in the U.S. and Poland. Thirdly, post-mortem recognition viability is assessed using more than 20 iris recognition algorithms, ranging from the classic (e.g., Gabor ﬁltering-based) to the modern (e.g., deep learning-based). Finally, we provide a medically informed commentary on post-mortem iris, analyze the reasons for recognition failures, and identify key directions for future research.},
  pages        = {136570--136593},
  journaltitle = {{IEEE} Access},
  shortjournal = {{IEEE} Access},
  author       = {Boyd, Aidan and Yadav, Shivangi and Swearingen, Thomas and Kuehlkamp, Andrey and Trokielewicz, Mateusz and Benjamin, Eric and Maciejewicz, Piotr and Chute, Dennis and Ross, Arun and Flynn, Patrick and Bowyer, Kevin and Czajka, Adam},
  urldate      = {2022-06-02},
  date         = {2020},
  langid       = {english},
  file         = {Boyd et al. - 2020 - Post-Mortem Iris Recognition—A Survey and Assessme.pdf:C\:\\Users\\na-ch\\Zotero\\storage\\HT5ZXT4Q\\Boyd et al. - 2020 - Post-Mortem Iris Recognition—A Survey and Assessme.pdf:application/pdf}
}

@article{abdullah_iris_2015,
  title    = {Iris Recognition Using Wavelet Transform and Artificial Neural Networks},
  abstract = {In this approach to get more accuracy of the iris recognition, is composed of many steps: capturing the iris image, determining the location of the iris boundaries, normalization, preprocessed using median filter to remove noise, using wavelet transform for two types of filter, Haar and Daubechies (db4), in order to extract the features and finally using the matching by artificial feed forward neural network with back propagation algorithm ({FFBNN}) for training and testing iris image. In this proposed system, two database systems are used. The first is {CASIA} database system (version 1.0) (Chinese Academy of Sciences Institute of Automation). And, the second is {REAL} database system by using real persons and each person takes many images for recognition through camera Mobile Type of Galaxy Note3. In {CASIA} System, the iris recognition rate for Haar filter was 84.2\% and for Daubechies filter was 92.8\%, while in Real system, the iris recognition rate for Haar filter was 90\% and for Daubechies filter was 98.7\%, this means the Daubechies filter was the best in time and error from the Haar filter. Finally, this system is efficient, because the performance measurement of {FAR} was 0\%. The results and the experiments were implemented by P4 computer and the software package {MATLAB} (R2011a).},
  pages    = {13},
  author   = {Abdullah, Dr Hadeel N},
  date     = {2015},
  langid   = {english},
  file     = {Abdullah - 2015 - Iris Recognition Using Wavelet Transform and Artif.PDF:C\:\\Users\\na-ch\\Zotero\\storage\\6WJAGCHN\\Abdullah - 2015 - Iris Recognition Using Wavelet Transform and Artif.PDF:application/pdf}
}

@misc{minaee_deepiris_2019,
  title      = {{DeepIris}: Iris Recognition Using A Deep Learning Approach},
  url        = {http://arxiv.org/abs/1907.09380},
  shorttitle = {{DeepIris}},
  abstract   = {Iris recognition has been an active research area during last few decades, because of its wide applications in security, from airports to homeland security border control. Different features and algorithms have been proposed for iris recognition in the past. In this paper, we propose an end-to-end deep learning framework for iris recognition based on residual convolutional neural network ({CNN}), which can jointly learn the feature representation and perform recognition. We train our model on a well-known iris recognition dataset using only a few training images from each class, and show promising results and improvements over previous approaches. We also present a visualization technique which is able to detect the important areas in iris images which can mostly impact the recognition results. We believe this framework can be widely used for other biometrics recognition tasks, helping to have a more scalable and accurate systems.},
  publisher  = {{arXiv}},
  author     = {Minaee, Shervin and Abdolrashidi, Amirali},
  urldate    = {2022-06-02},
  date       = {2019-07-22},
  langid     = {english},
  eprinttype = {arxiv},
  eprint     = {1907.09380 [cs]},
  note       = {Number: {arXiv}:1907.09380},
  keywords   = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning},
  file       = {Minaee and Abdolrashidi - 2019 - DeepIris Iris Recognition Using A Deep Learning A.pdf:C\:\\Users\\na-ch\\Zotero\\storage\\HKSE335Z\\Minaee and Abdolrashidi - 2019 - DeepIris Iris Recognition Using A Deep Learning A.pdf:application/pdf}
}

@misc{zeiler_visualizing_2013,
  title      = {Visualizing and Understanding Convolutional Networks},
  url        = {http://arxiv.org/abs/1311.2901},
  abstract   = {Large Convolutional Network models have recently demonstrated impressive classiﬁcation performance on the {ImageNet} benchmark (Krizhevsky et al., 2012). However there is no clear understanding of why they perform so well, or how they might be improved. In this paper we address both issues. We introduce a novel visualization technique that gives insight into the function of intermediate feature layers and the operation of the classiﬁer. Used in a diagnostic role, these visualizations allow us to ﬁnd model architectures that outperform Krizhevsky et al. on the {ImageNet} classiﬁcation benchmark. We also perform an ablation study to discover the performance contribution from diﬀerent model layers. We show our {ImageNet} model generalizes well to other datasets: when the softmax classiﬁer is retrained, it convincingly beats the current state-of-the-art results on Caltech-101 and Caltech-256 datasets.},
  publisher  = {{arXiv}},
  author     = {Zeiler, Matthew D. and Fergus, Rob},
  urldate    = {2022-06-02},
  date       = {2013-11-28},
  langid     = {english},
  eprinttype = {arxiv},
  eprint     = {1311.2901 [cs]},
  note       = {Number: {arXiv}:1311.2901},
  keywords   = {Computer Science - Computer Vision and Pattern Recognition},
  file       = {Zeiler and Fergus - 2013 - Visualizing and Understanding Convolutional Networ.pdf:C\:\\Users\\na-ch\\Zotero\\storage\\93QBRAJ9\\Zeiler and Fergus - 2013 - Visualizing and Understanding Convolutional Networ.pdf:application/pdf}
}

@misc{minaee_experimental_2017,
  title      = {An Experimental Study of Deep Convolutional Features For Iris Recognition},
  url        = {http://arxiv.org/abs/1702.01334},
  abstract   = {Iris is one of the popular biometrics that is widely used for identity authentication. Different features have been used to perform iris recognition in the past. Most of them are based on hand-crafted features designed by biometrics experts. Due to tremendous success of deep learning in computer vision problems, there has been a lot of interest in applying features learned by convolutional neural networks on general image recognition to other tasks such as segmentation, face recognition, and object detection. In this paper, we have investigated the application of deep features extracted from {VGG}-Net for iris recognition. The proposed scheme has been tested on two well-known iris databases, and has shown promising results with the best accuracy rate of 99.4\%, which outperforms the previous best result.},
  publisher  = {{arXiv}},
  author     = {Minaee, Shervin and Abdolrashidi, Amirali and Wang, Yao},
  urldate    = {2022-06-04},
  date       = {2017-02-04},
  langid     = {english},
  eprinttype = {arxiv},
  eprint     = {1702.01334 [cs]},
  note       = {Number: {arXiv}:1702.01334},
  keywords   = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning},
  annotation = {Comment: {IEEE} Signal Processing in Medicine and Biology Symposium, 2016},
  file       = {Minaee et al. - 2017 - An Experimental Study of Deep Convolutional Featur.pdf:C\:\\Users\\na-ch\\Zotero\\storage\\MJ64GKHA\\Minaee et al. - 2017 - An Experimental Study of Deep Convolutional Featur.pdf:application/pdf}
}

@misc{boyd_deep_2020,
  title      = {Deep Learning-Based Feature Extraction in Iris Recognition: Use Existing Models, Fine-tune or Train From Scratch?},
  url        = {http://arxiv.org/abs/2002.08916},
  shorttitle = {Deep Learning-Based Feature Extraction in Iris Recognition},
  abstract   = {Modern deep learning techniques can be employed to generate effective feature extractors for the task of iris recognition. The question arises: should we train such structures from scratch on a relatively large iris image dataset, or it is better to ﬁne-tune the existing models to adapt them to a new domain? In this work we explore ﬁve different sets of weights for the popular {ResNet}-50 architecture to ﬁnd out whether iris-speciﬁc feature extractors perform better than models trained for non-iris tasks. Features are extracted from each convolutional layer and the classiﬁcation accuracy achieved by a Support Vector Machine is measured on a dataset that is disjoint from the samples used in training of the {ResNet}-50 model. We show that the optimal training strategy is to ﬁne-tune an off-the-shelf set of weights to the iris recognition domain. This approach results in greater accuracy than both off-the-shelf weights and a model trained from scratch. The winning, ﬁne-tuned approach also shows an increase in performance when compared to previous work, in which only off-the-shelf (not ﬁnetuned) models were used in iris feature extraction. We make the best-performing {ResNet}-50 model, ﬁne-tuned with more than 360,000 iris images, publicly available along with this paper.},
  publisher  = {{arXiv}},
  author     = {Boyd, Aidan and Czajka, Adam and Bowyer, Kevin},
  urldate    = {2022-06-04},
  date       = {2020-02-20},
  langid     = {english},
  eprinttype = {arxiv},
  eprint     = {2002.08916 [cs]},
  note       = {Number: {arXiv}:2002.08916},
  keywords   = {Computer Science - Computer Vision and Pattern Recognition},
  annotation = {Comment: Presented at {BTAS} 2019},
  file       = {Boyd et al. - 2020 - Deep Learning-Based Feature Extraction in Iris Rec.pdf:C\:\\Users\\na-ch\\Zotero\\storage\\G35UNBNH\\Boyd et al. - 2020 - Deep Learning-Based Feature Extraction in Iris Rec.pdf:application/pdf}
}

@article{liu_efficient_2021,
  title        = {An Efficient and Accurate Iris Recognition Algorithm Based on a Novel Condensed 2-ch Deep Convolutional Neural Network},
  volume       = {21},
  issn         = {1424-8220},
  url          = {https://www.mdpi.com/1424-8220/21/11/3721},
  doi          = {10.3390/s21113721},
  abstract     = {Recently, deep learning approaches, especially convolutional neural networks ({CNNs}), have attracted extensive attention in iris recognition. Though {CNN}-based approaches realize automatic feature extraction and achieve outstanding performance, they usually require more training samples and higher computational complexity than the classic methods. This work focuses on training a novel condensed 2-channel (2-ch) {CNN} with few training samples for efﬁcient and accurate iris identiﬁcation and veriﬁcation. A multi-branch {CNN} with three well-designed online augmentation schemes and radial attention layers is ﬁrst proposed as a high-performance basic iris classiﬁer. Then, both branch pruning and channel pruning are achieved by analyzing the weight distribution of the model. Finally, fast ﬁnetuning is optionally applied, which can signiﬁcantly improve the performance of the pruned {CNN} while alleviating the computational burden. In addition, we further investigate the encoding ability of 2-ch {CNN} and propose an efﬁcient iris recognition scheme suitable for large database application scenarios. Moreover, the gradient-based analysis results indicate that the proposed algorithm is robust to various image contaminations. We comprehensively evaluated our algorithm on three publicly available iris databases for which the results proved satisfactory for real-time iris recognition.},
  pages        = {3721},
  number       = {11},
  journaltitle = {Sensors},
  shortjournal = {Sensors},
  author       = {Liu, Guoyang and Zhou, Weidong and Tian, Lan and Liu, Wei and Liu, Yingjian and Xu, Hanwen},
  urldate      = {2022-06-09},
  date         = {2021-05-27},
  langid       = {english},
  file         = {Liu et al. - 2021 - An Efficient and Accurate Iris Recognition Algorit.pdf:C\:\\Users\\na-ch\\Zotero\\storage\\ZR5DL6H7\\Liu et al. - 2021 - An Efficient and Accurate Iris Recognition Algorit.pdf:application/pdf}
}

@article{szymkowski_iris-based_2021,
  title        = {Iris-based human identity recognition with machine learning methods and discrete fast Fourier transform},
  volume       = {17},
  issn         = {1614-5046, 1614-5054},
  url          = {https://link.springer.com/10.1007/s11334-021-00392-9},
  doi          = {10.1007/s11334-021-00392-9},
  abstract     = {One of the most important modules of computer systems is the one that is responsible for user safety. It was proven that simple passwords and logins cannot guarantee high efficiency and are easy to obtain by the hackers. The well-known alternative is identity recognition based on biometrics. In recent years, more interest was observed in iris as a biometrics trait. It was caused due to high efficiency and accuracy guaranteed by this measurable feature. The consequences of such interest are observable in the literature. There are multiple, diversified approaches proposed by different authors. However, neither of them uses discrete fast Fourier transform ({DFFT}) components to describe iris sample. In this work, the authors present their own approach to iris-based human identity recognition with {DFFT} components selected with principal component analysis algorithm. For classification, three algorithms were used—k-nearest neighbors, support vector machines and artificial neural networks. Performed tests have shown that satisfactory results can be obtained with the proposed method.},
  pages        = {309--317},
  number       = {3},
  journaltitle = {Innovations in Systems and Software Engineering},
  shortjournal = {Innovations Syst Softw Eng},
  author       = {Szymkowski, Maciej and Jasiński, Piotr and Saeed, Khalid},
  urldate      = {2022-06-09},
  date         = {2021-09},
  langid       = {english},
  file         = {Szymkowski et al. - 2021 - Iris-based human identity recognition with machine.pdf:C\:\\Users\\na-ch\\Zotero\\storage\\ZUCD95NS\\Szymkowski et al. - 2021 - Iris-based human identity recognition with machine.pdf:application/pdf}
}

@inproceedings{lozej_end--end_2018,
  location   = {San Carlos},
  title      = {End-to-End Iris Segmentation Using U-Net},
  isbn       = {978-1-5386-7506-9},
  url        = {https://ieeexplore.ieee.org/document/8464213/},
  doi        = {10.1109/IWOBI.2018.8464213},
  abstract   = {Iris segmentation is an important research topic that received signiﬁcant attention from the research community over the years. Traditional iris segmentation techniques have typically been focused on hand-crafted procedures that, nonetheless, achieved remarkable segmentation performance even with images captured in difﬁcult settings. With the success of deeplearning models, researchers are increasingly looking towards convolutional neural networks ({CNNs}) to further improve on the accuracy of existing iris segmentation techniques and several {CNN}-based techniques have already been presented recently in the literature. In this paper we also consider deep-learning models for iris segmentation and present an iris segmentation approach based on the popular U-Net architecture. Our model is trainable end-to-end and, hence, avoids the need for hand designing the segmentation procedure. We evaluate the model on the {CASIA} dataset and report encouraging results in comparison to existing techniques used in this area.},
  eventtitle = {2018 {IEEE} International Work Conference on Bioinspired Intelligence ({IWOBI})},
  pages      = {1--6},
  booktitle  = {2018 {IEEE} International Work Conference on Bioinspired Intelligence ({IWOBI})},
  publisher  = {{IEEE}},
  author     = {Lozej, Jus and Meden, Blaz and Struc, Vitomir and Peer, Peter},
  urldate    = {2022-06-09},
  date       = {2018-07},
  langid     = {english},
  file       = {Lozej et al. - 2018 - End-to-End Iris Segmentation Using U-Net.pdf:C\:\\Users\\na-ch\\Zotero\\storage\\8G296SQY\\Lozej et al. - 2018 - End-to-End Iris Segmentation Using U-Net.pdf:application/pdf}
}

@article{daugman_normalization_1993,
  title        = {High confidence visual recognition of persons by a test of statistical independ-ence.},
  volume       = {15},
  number       = {11},
  journaltitle = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  author       = {Daugman, John G.},
  date         = {1993-11}
}

@article{4767851,
  author   = {Canny, John},
  journal  = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  title    = {A Computational Approach to Edge Detection},
  year     = {1986},
  volume   = {PAMI-8},
  number   = {6},
  pages    = {679-698},
  abstract = {This paper describes a computational approach to edge detection. The success of the approach depends on the definition of a comprehensive set of goals for the computation of edge points. These goals must be precise enough to delimit the desired behavior of the detector while making minimal assumptions about the form of the solution. We define detection and localization criteria for a class of edges, and present mathematical forms for these criteria as functionals on the operator impulse response. A third criterion is then added to ensure that the detector has only one response to a single edge. We use the criteria in numerical optimization to derive detectors for several common image features, including step edges. On specializing the analysis to step edges, we find that there is a natural uncertainty principle between detection and localization performance, which are the two main goals. With this principle we derive a single operator shape which is optimal at any scale. The optimal detector has a simple approximate implementation in which edges are marked at maxima in gradient magnitude of a Gaussian-smoothed image. We extend this simple detector using operators of several widths to cope with different signal-to-noise ratios in the image. We present a general method, called feature synthesis, for the fine-to-coarse integration of information from operators at different scales. Finally we show that step edge detector performance improves considerably as the operator point spread function is extended along the edge.},
  keywords = {},
  doi      = {10.1109/TPAMI.1986.4767851},
  issn     = {1939-3539},
  month    = {Nov}
}

  @article{DeMarsico2016IrisRT,
  title   = {Iris recognition through machine learning techniques: A survey},
  author  = {M. De Marsico and Alfredo Petrosino and Stefano Ricciardi},
  journal = {Pattern Recognit. Lett.},
  year    = {2016},
  volume  = {82},
  pages   = {106-115}
}

@article{10.1016/j.cogsys.2018.09.029,
  author     = {Susitha, N. and Subban, Ravi},
  title      = {Reliable Pupil Detection and Iris Segmentation Algorithm Based on SPS},
  year       = {2019},
  issue_date = {Oct 2019},
  publisher  = {Elsevier Science Publishers B. V.},
  address    = {NLD},
  volume     = {57},
  number     = {C},
  issn       = {1389-0417},
  url        = {https://doi.org/10.1016/j.cogsys.2018.09.029},
  doi        = {10.1016/j.cogsys.2018.09.029},
  journal    = {Cogn. Syst. Res.},
  month      = {oct},
  pages      = {78–84},
  numpages   = {7},
  keywords   = {Pupil detection, Iris segmentation, Iris detection}
}

@inproceedings{7498983,
  author    = {Bakshi, Kavitha Amit and Prasad, B.G. and Sneha K.},
  booktitle = {2015 International Conference on Emerging Research in Electronics, Computer Science and Technology (ICERECT)},
  title     = {An efficient iris code storing and searching technique for Iris Recognition using non-homogeneous K-d tree},
  year      = {2015},
  volume    = {},
  number    = {},
  pages     = {34-38},
  doi       = {10.1109/ERECT.2015.7498983}
}

@book{Goodfellow-et-al-2016,
    title={Deep Learning},
    author={Ian Goodfellow and Yoshua Bengio and Aaron Courville},
    publisher={MIT Press},
    note={\url{http://www.deeplearningbook.org}},
    year={2016}
}