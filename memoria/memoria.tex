\documentclass[a4paper,12pt,twoside]{memoir}

%otros
\usepackage{listings}
\interfootnotelinepenalty=10000
\usepackage{makecell}
\usepackage{listings}
\lstset{
  basicstyle=\ttfamily,
  columns=fullflexible,
  frame=single,
  breaklines=true,
  postbreak=\mbox{\textcolor{red}{$\hookrightarrow$}\space},
}
\usepackage{dirtree}

% Castellano
\usepackage[spanish,es-tabla]{babel}
\selectlanguage{spanish}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{lmodern} % Scalable font
\usepackage{microtype}
\usepackage{placeins}

\RequirePackage{booktabs}
\RequirePackage[table]{xcolor}
\RequirePackage{xtab}
\RequirePackage{multirow} 

% Links
\usepackage[colorlinks]{hyperref}
\hypersetup{
	allcolors = {blue}
}

% Ecuaciones
\usepackage{amsmath}
\usepackage{multirow}

% Rutas de fichero / paquete
\newcommand{\ruta}[1]{{\sffamily #1}}

% Párrafos
\nonzeroparskip

% Huérfanas y viudas
\widowpenalty100000
\clubpenalty100000

% Evitar solapes en el header
\nouppercaseheads

% Imagenes
\usepackage{graphicx}
\newcommand{\imagen}[4]{
	\begin{figure}[!h]
		\centering
		\includegraphics[width=0.9\textwidth]{#1}
		\caption[{#3}]{#2}\label{#4}
	\end{figure}
	\FloatBarrier
}

\newcommand{\imagenflotante}[2]{
	\begin{figure}%[!h]
		\centering
		\includegraphics[width=0.9\textwidth]{#1}
		\caption{#2}\label{fig:#1}
	\end{figure}
}

\newcommand{\imagenPequenya}[4]{
	\begin{figure}[!h]
		\centering
		\includegraphics[width=50mm]{#1}
		\caption[{#3}]{#2}\label{#4}
	\end{figure}
	\FloatBarrier
}



% El comando \figura nos permite insertar figuras comodamente, y utilizando
% siempre el mismo formato. Los parametros son:
% 1 -> Porcentaje del ancho de página que ocupará la figura (de 0 a 1)
% 2 --> Fichero de la imagen
% 3 --> Texto a pie de imagen
% 4 --> Etiqueta (label) para referencias
% 5 --> Opciones que queramos pasarle al \includegraphics
% 6 --> Opciones de posicionamiento a pasarle a \begin{figure}
\newcommand{\figuraConPosicion}[6]{%
  \setlength{\anchoFloat}{#1\textwidth}%
  \addtolength{\anchoFloat}{-4\fboxsep}%
  \setlength{\anchoFigura}{\anchoFloat}%
  \begin{figure}[#6]
    \begin{center}%
      \Ovalbox{%
        \begin{minipage}{\anchoFloat}%
          \begin{center}%
            \includegraphics[width=\anchoFigura,#5]{#2}%
            \caption{#3}%
            \label{#4}%
          \end{center}%
        \end{minipage}
      }%
    \end{center}%
  \end{figure}%
}

%
% Comando para incluir imágenes en formato apaisado (sin marco).
\newcommand{\figuraApaisadaSinMarco}[5]{%
  \begin{figure}%
    \begin{center}%
    \includegraphics[angle=90,height=#1\textheight,#5]{#2}%
    \caption{#3}%
    \label{#4}%
    \end{center}%
  \end{figure}%
}
% Para las tablas
\newcommand{\otoprule}{\midrule [\heavyrulewidth]}
%
% Nuevo comando para tablas pequeñas (menos de una página).
\newcommand{\tablaSmall}[5]{%
 \begin{table}[h!]
  \begin{center}
   \rowcolors {2}{gray!35}{}
   \begin{tabular}{#2}
    \toprule
    #4
    \otoprule
    #5
    \bottomrule
   \end{tabular}
   \caption{#1}
   \label{tabla:#3}
  \end{center}
 \end{table}
}

%
% Nuevo comando para tablas pequeñas (menos de una página).
\newcommand{\tablaSmallSinColores}[5]{%
 \begin{table}[h!]
  \begin{center}
   \begin{tabular}{#2}
    \toprule
    #4
    \otoprule
    #5
    \bottomrule
   \end{tabular}
   \caption{#1}
   \label{tabla:#3}
  \end{center}
 \end{table}
}

\newcommand{\tablaApaisadaSmall}[5]{%
\begin{landscape}
  \begin{table}
   \begin{center}
    \rowcolors {2}{gray!35}{}
    \begin{tabular}{#2}
     \toprule
     #4
     \otoprule
     #5
     \bottomrule
    \end{tabular}
    \caption{#1}
    \label{tabla:#3}
   \end{center}
  \end{table}
\end{landscape}
}

%
% Nuevo comando para tablas grandes con cabecera y filas alternas coloreadas en gris.
\newcommand{\tabla}[6]{%
  \begin{center}
    \tablefirsthead{
      \toprule
      #5
      \otoprule
    }
    \tablehead{
      \multicolumn{#3}{l}{\small\sl continúa desde la página anterior}\\
      \toprule
      #5
      \otoprule
    }
    \tabletail{
      \hline
      \multicolumn{#3}{r}{\small\sl continúa en la página siguiente}\\
    }
    \tablelasttail{
      \hline
    }
    \bottomcaption{#1}
    \rowcolors {2}{gray!35}{}
    \begin{xtabular}{#2}
      #6
      \bottomrule
    \end{xtabular}
    \label{tabla:#4}
  \end{center}
}

%
% Nuevo comando para tablas grandes con cabecera.
\newcommand{\tablaSinColores}[6]{%
  \begin{center}
    \tablefirsthead{
      \toprule
      #5
      \otoprule
    }
    \tablehead{
      \multicolumn{#3}{l}{\small\sl continúa desde la página anterior}\\
      \toprule
      #5
      \otoprule
    }
    \tabletail{
      \hline
      \multicolumn{#3}{r}{\small\sl continúa en la página siguiente}\\
    }
    \tablelasttail{
      \hline
    }
    \bottomcaption{#1}
    \begin{xtabular}{#2}
      #6
      \bottomrule
    \end{xtabular}
    \label{tabla:#4}
  \end{center}
}

%
% Nuevo comando para tablas grandes sin cabecera.
\newcommand{\tablaSinCabecera}[5]{%
  \begin{center}
    \tablefirsthead{
      \toprule
    }
    \tablehead{
      \multicolumn{#3}{l}{\small\sl continúa desde la página anterior}\\
      \hline
    }
    \tabletail{
      \hline
      \multicolumn{#3}{r}{\small\sl continúa en la página siguiente}\\
    }
    \tablelasttail{
      \hline
    }
    \bottomcaption{#1}
  \begin{xtabular}{#2}
    #5
   \bottomrule
  \end{xtabular}
  \label{tabla:#4}
  \end{center}
}



\definecolor{cgoLight}{HTML}{EEEEEE}
\definecolor{cgoExtralight}{HTML}{FFFFFF}

%
% Nuevo comando para tablas grandes sin cabecera.
\newcommand{\tablaSinCabeceraConBandas}[5]{%
  \begin{center}
    \tablefirsthead{
      \toprule
    }
    \tablehead{
      \multicolumn{#3}{l}{\small\sl continúa desde la página anterior}\\
      \hline
    }
    \tabletail{
      \hline
      \multicolumn{#3}{r}{\small\sl continúa en la página siguiente}\\
    }
    \tablelasttail{
      \hline
    }
    \bottomcaption{#1}
    \rowcolors[]{1}{cgoExtralight}{cgoLight}

  \begin{xtabular}{#2}
    #5
   \bottomrule
  \end{xtabular}
  \label{tabla:#4}
  \end{center}
}


\graphicspath{ {./img/} }

% Capítulos
\chapterstyle{bianchi}
\newcommand{\capitulo}[2]{
	\setcounter{chapter}{#1}
	\setcounter{section}{0}
	\chapter*{#2}
	\addcontentsline{toc}{chapter}{#1. #2}
	\markboth{#2}{#2}
}

% Apéndices
\renewcommand{\appendixname}{Apéndice}
\renewcommand*\cftappendixname{\appendixname}

\newcommand{\apendice}[1]{
	%\renewcommand{\thechapter}{A}
	\chapter{#1}
}

\renewcommand*\cftappendixname{\appendixname\ }

% Formato de portada
\makeatletter
\usepackage{xcolor}
\newcommand{\tutor}[1]{\def\@tutor{#1}}
\newcommand{\course}[1]{\def\@course{#1}}
\definecolor{cpardoBox}{HTML}{E6E6FF}
\def\maketitle{
  \null
  \thispagestyle{empty}
  % Cabecera ----------------
\begin{center}%
	{\noindent\Huge Universidades de Burgos, León y Valladolid}\vspace{.5cm}%
	
	{\noindent\Large Máster universitario}\vspace{.5cm}%
	
	{\noindent\Huge \textbf{Inteligencia de Negocio y Big~Data en Entornos Seguros}}\vspace{.5cm}%
\end{center}%

\begin{center}%
	\includegraphics[height=3cm]{img/escudoUBU} \hspace{1cm}
	\includegraphics[height=3cm]{img/escudoUVA} \hspace{1cm}
	\includegraphics[height=3cm]{img/escudoULE} \vspace{1cm}%
\end{center}%

  \vfill
  % Título proyecto y escudo informática ----------------
  \colorbox{cpardoBox}{%
    \begin{minipage}{.9\textwidth}
      \vspace{.5cm}\Large
      \begin{center}
      \textbf{TFM del Máster Inteligencia de Negocio y Big Data en Entornos Seguros}\vspace{.6cm}\\
      \textbf{\LARGE\@title{}}
      \end{center}
      \vspace{.2cm}
    \end{minipage}

  }%
  \hfill
  \vfill
  % Datos de alumno, curso y tutores ------------------
  \begin{center}%
  {%
    \noindent\LARGE
    Presentado por \@author{}\\ 
    en Universidad de Burgos --- \@date{}\\
    Tutores: \@tutor{}\\
  }%
  \end{center}%
  \null
  \cleardoublepage
  }
\makeatother

\newcommand{\nombre}{Ignacio Ponsoda Llorens} %%% cambio de comando

% Datos de portada
\title{Clasificación de individuos a partir de imágenes oculares y redes neuronales pre-entrenadas.}
\author{\nombre}
\tutor{Dr. José Francisco Díez Pastor y Dr. Pedro Latorre Carmona}
\date{\today}

\begin{document}

\maketitle


\newpage\null\thispagestyle{empty}\newpage


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\thispagestyle{empty}


\noindent
\begin{center}%
	{\noindent\Huge Universidades de Burgos, León y Valladolid}\vspace{.5cm}%
	
\begin{center}%
	\includegraphics[height=3cm]{img/escudoUBU} \hspace{1cm}
	\includegraphics[height=3cm]{img/escudoUVA} \hspace{1cm}
	\includegraphics[height=3cm]{img/escudoULE} \vspace{1cm}%
\end{center}%

	{\noindent\Large \textbf{Máster universitario en Inteligencia de Negocio y Big~Data en Entornos Seguros}}\vspace{.5cm}%
\end{center}%



\noindent D. José Francisco Díez Pastor, profesor del departamento de Ingeniería Informática, área de Lenguajes y Sistemas Informáticos, y
\noindent D. Pedro Latorre Carmona, profesor del departamento de Ingeniería Informática, área de Lenguajes y Sistemas Informáticos.

\noindent Exponen:

\noindent Que el alumno  \nombre, con DNI 21698927Z, ha realizado el Trabajo final de Máster en Inteligencia de Negocio y Big Data en Entornos Seguros 
          titulado 'Clasificación de individuos a partir de imágenes oculares y redes neuronales pre-entrenadas'. 

\noindent Y que dicho trabajo ha sido realizado por el alumno bajo la dirección de los que suscriben, en virtud de lo cual se autoriza su presentación y defensa.

\begin{center} %\large
En Burgos, {\large \today}
\end{center}

\vfill\vfill\vfill

% Author and supervisor
\begin{minipage}{0.45\textwidth}
\begin{flushleft} %\large
Vº. Bº. del Tutor:\\[2cm]
D. José Francisco Díez Pastor
\end{flushleft}
\end{minipage}
\hfill
\begin{minipage}{0.45\textwidth}
\begin{flushleft} %\large
Vº. Bº. del Tutor:\\[2cm]
D. Pedro Latorre Carmona
\end{flushleft}
\end{minipage}
\hfill

\vfill

% para casos con solo un tutor comentar lo anterior
% y descomentar lo siguiente
%Vº. Bº. del Tutor:\\[2cm]
%D. nombre tutor


\newpage\null\thispagestyle{empty}\newpage




\frontmatter

% Abstract en castellano
\renewcommand*\abstractname{Resumen}
\begin{abstract}

La utilización de la biometría para mejorar la seguridad, principalmente en lo referente al acceso de dispositivos electrónicos, es un recurso ampliamente empleado en la actualidad, siendo el iris uno de los elementos biométricos que mayores dificultades presentan para la suplantación de identidad. 

La identificación de personas a través del iris se lleva a cabo extrayendo sus características más relevantes, comúnmente utilizando técnicas empíricas. No obstante, las redes neuronales han demostrado ser útiles para extraer las características del iris. Esta extracción se puede llevar a cabo no solo entrenando una red neuronal desde cero, sino también adaptando una ya pre-entrenada con imágenes donde el iris ha sido aislado.

Respecto a la segunda fórmula se plantean dos preguntas. En primer lugar, ¿Es necesario aislar el iris para llevar a cabo la adaptación de la red neuronal, o esta podría llevarse a cabo también de forma eficiente con las imágenes oculares completas? En segundo lugar, ¿una vez que se ha adaptado la red neuronal a el conjunto de datos, sería posible que esta llevase a cabo, no solo la extracción de características sino también la clasificación?

En este proyecto se han adaptado redes neuronales que inicialmente habían sido entrenadas en el reconocimiento de objetos, para que sean capaces de identificar a un individuo utilizando su imagen ocular. 

Para ello, se han utilizado dos enfoques. En un primer enfoque, se han adaptado las redes neuronales con imágenes oculares completas. En el segundo enfoque, se han adaptado las redes neuronales utilizando imágenes exclusivamente de la zona del iris, la cual es a priori la zona de la imagen ocular que mejor permite la identificación de individuos.

Además, se han utilizado técnicas de aumento del número de muestras del conjunto de datos original, para así poder contar con un mayor número de muestras de cada individuo y también, mejorar la robustez de las redes neuronales adaptadas.

Los resultados muestran que las mejores tasas de clasificación se han dado en el enfoque donde se utilizaba la imagen ocular completa, sin que las técnicas de ampliación del conjunto de datos hayan permitido mejorar la tasa de clasificación. 

Como futuras líneas de trabajo, se establecen dos. Por un lado, la adaptación de nuevas redes neuronales pre-entrenadas para comprobar cual se adapta mejor a esta metodología. Por otro lado, verificar los modelos resultantes con imágenes que hayan sufrido alteraciones, para comprobar su robustez.


\end{abstract}

\renewcommand*\abstractname{Descriptores}
\begin{abstract}
biometría, iris, redes neuronales, imágenes oculares, \textit{fine-tuning}, \textit{data augmentation}, CASIA
\end{abstract}

\clearpage

% Abstract en inglés 
\renewcommand*\abstractname{Abstract}
\begin{abstract}

  The use of biometrics to improve security,
  especially when it comes to access to electronic devices, it is a resource widely used today and, the iris is one of the biometric elements that present the greatest difficulties for identity fraud.

  The identification of people through the iris is carried out by extracting their most relevant characteristics, commonly using empirical techniques. Nonetheless, neural networks have proven useful for extracting features from the iris. This extraction can be carried out not only by training a neural network from scratch but also by adapting an already pre-trained one with images where the iris has been isolated.

  Regarding the second formula, two questions arise. First, is it necessary to isolate the iris to carry out the adaptation of the neural network, or could it also be carried out efficiently with full eye images? And secondly, once the neural network has been adapted to the dataset, would it be possible for it to perform not only feature extraction but also classification?
  
  In this project, neural networks that had initially been trained in object recognition have been adapted so that they are capable of identifying an individual using their eye image.
  
  To do this, two approaches have been used. In a first approach, neural networks have been adapted with whole eye images. In the second approach, the neural networks have been adapted using images exclusively of the iris area, which is a priori the area of the eye image that best allows the identification of individuals.

  In addition, techniques have been used to increase the number of samples of the original data set, in order to have a greater number of samples from each individual and also improve the robustness of the adapted neural networks.

  The results show that the best classification rates have been given in the approach where the complete ocular image was used, without the techniques of enlarging the data set having allowed improving the classification rate.

  As future lines of work, two are established. On the one hand, the adaptation of new pre-trained neural networks to check which one best suits this methodology. On the other hand, verify the resulting models with images that have suffered alterations, to check their robustness.
  \end{abstract}

\renewcommand*\abstractname{Keywords}
\begin{abstract}
biometrics, iris, neural networks, fine-tuning, data augmentation
\end{abstract}

\clearpage

% Indices
\tableofcontents

\clearpage

\listoffigures

\clearpage

\listoftables
\clearpage

\mainmatter

\part*{Memoria}
\addcontentsline{toc}{part}{Memoria}

\include{./tex/1_Introduccion}
\include{./tex/2_Objetivos_del_proyecto}
\include{./tex/3_Conceptos_teoricos}
\include{./tex/4_Tecnicas_y_herramientas}
\include{./tex/5_Aspectos_relevantes_del_desarrollo_del_proyecto}
\include{./tex/6_Trabajos_relacionados}
\include{./tex/7_Conclusiones_Lineas_de_trabajo_futuras}


%\renewcommand\chaptername{Anexo}
%\renewcommand\thechapter{\Roman{chapter}}
%\setcounter{chapter}{0}

% Añadir entrada en el índice: Anexos
\appendix
\addcontentsline{toc}{part}{Apéndices}
\part*{Apéndices}

\include{./tex/A_Plan_proyecto}
\include{./tex/B_Requisitos}
\include{./tex/C_Diseno}
\include{./tex/D_Manual_programador}
%\include{./tex/E_Manual_usuario}


\bibliographystyle{plain}
\bibliography{bibliografia}

\end{document}
