\apendice{Documentación técnica de programación}

\section{Introducción}

En este apartado se determinará la forma de proceder para poder replicar el proyecto por parte de programadores. En el se explica la estructura de los directorios así como la función de las distintas partes del código.

\section{Estructura de directorios}

\begin{itemize}
    \item 06\_Models contiene los modelos finales
    \item img contiene las imágenes utilizadas en el propio repositorio
    \item memoria, incluye la memoria
    \begin{itemize}
        \item tex, contiene los archivos tex
        \item img, contiene las imágenes del proyecto
    \end{itemize}
        \item src, incluye el código del proyecto con distintas versiones
\end{itemize}

\section{Manual del programador}


Los \textit{notebooks} del proyecto se pueden explorar en cualquier plataforma compatible con Jupyter notebooks.

\subsection{\textit{Notebook} \texttt{pipeline.ipynb}} \label{anx:pipeline}

El {\textit{notebook} \texttt{pipeline.ipynb} contiene el código principal del proyecto. A continuación se detallan sus partes.

\subsubsection{Configuración}

La configuración del \textit{pipeline} se muestra a continuación. En ella, se establece primero una configuración general, es decir, que es aplicable a
las distintas secciones. En ella se han configurado las rutas en las que se guardan los distintos \textit{datasets}. Si todo el código es ejecutado, solo el
\textit{'root-dir'} se mantendrá, y el resto se irán sobrescribiendo cuando se cree el propio conjunto de datos. No obstante, la capacidad de establecer todas
las rutas en la configuración es lo que nos permite cambiar el orden de las secciones en el \textit{pipeline}. 

\begin{itemize}
    \item \textit{tratardDataset}
    \begin{itemize}
        \item \textit{general\_train\_size}, tamaño del conjunto de datos que será utilizado para el entrenamiento [Valor del 0-1].
        \item \textit{show\_first}, mostrar primera imagen [boolean].
    \end{itemize}
    \item \textit{dataAugmentation}
    \begin{itemize}
        \item \textit{gaussianNoise}, aplicación del ruido Gaussiano [boolean].
        \item \textit{stdGN}, valores de ruido Gaussiano a aplicar en las imágenes [valores menores de 10].
        \item \textit{afinTransformation}, aplicación de transformaciones afines [boolean].
    \end{itemize}
    \item \textit{segmentation}
    \begin{itemize}
        \item \textit{redNeuronal}, nombre de la red neuronal a utilizar [extensión .h5].
        \item \textit{verImagenV1}, ver la imagen producida [boolean].
    \end{itemize}
    \item \textit{CNN\_classification}
    \begin{itemize}
        \item \textit{dataset\_dir}, directorio a utilizar ['raw', para la imagen ocular completa o 'normalizado', para la imagen del iris aislada].
        \item \textit{verImagenV1}, ver la imagen producida [boolean].
        \item \textit{CNN\_weights}, establecer de donde utilizar los pesos para la red neuronal [imagenet, None, o se le pasa un directorio con los pesos].
        \item \textit{train\_size}, tamaño del conjunto de datos de entrenamiento [0-1].
        \item \textit{test\_size}, tamaño del conjunto de datos de testeo [0-1].
        \item \textit{batch\_size}, tamaño del \textit{batch} [debe de ser menor del tamaño del conjunto de datos].
        \item \textit{epochs1}, establecer el tamaño del \textit{epochs} para entrenar al primer modelo [10-100].
        \item \textit{plt\_accuracy1}, mostrar gráfica con el \textit{accuracy} del primer modelo [boolean].
        \item \textit{epochs2}, establecer el tamaño del \textit{epochs} para entrenar al segundo modelo [8-80].
        \item \textit{plt\_accuracy2}, mostrar gráfica con el \textit{accuracy} del segundo modelo[boolean].
        \item \textit{epochs3}, establecer el tamaño del \textit{epochs} para entrenar al tercer modelo [8-50].
        \item \textit{plt\_accuracy3}, mostrar gráfica con el \textit{accuracy} del tercer modelo[boolean].
        \item \textit{results\_array}, mostrar el \textit{array} de resultados [boolean].
        \item \textit{save\_model}, guardar el modelo [boolean].
        \item \textit{save\_model\_name}, nombre con el que guardar el modelo [texto].
    \end{itemize}
\end{itemize}


\begin{lstlisting}[language=Python] 

confi_dict = {

    'general':{
        'root_dir':r"/home/root_folder",
        'dataset_dir': "CASIA-IrisV1",
        'dataset_unif_dir': r"./CASIA-IrisV1_unif",
        'dataset_unif_dir_aug':r"./CASIA-IrisV1_unif_aug",
        'dataset_unif_segv2_edg_norm_dir' : r"./CASIA-IrisV1_unif_segv2_edg_norm",
        'dataset_unif_dir':r"./CASIA-IrisV1_unif_aug",
        'dataset_unif_segv2_edg_norm_dir' : r"./CASIA-IrisV1_unif_aug_segv2_edg_norm",
        'dataset_unif_dir': r"./CASIA-IrisV1_reservado"
    },

    '1_tratarDataset':{
        'general_train_size': 0.7,
        'show_first' : False
    },

    '1.1_dataAugmentation':{
        'gaussianNoise' : True,
        'stdGN': [2.5, 5, 7.5],
        'afinTransformation': True
    },

    '2.1_segmentation':{
        'redNeuronal' : "Iris_unet_d5.h5", 
        'verImagenV1' : False
    },
    
    # Dataset dir can be "normalizado" or "raw"

    '4_CNN_classification' :{
        'dataset_dir' : "normalizado",
        'CNN_weights' : "imagenet",
        'train_size' : 0.7, 
        'test_size' : 0.3, 
        'batch_size' : 10,
        'epochs1' : 50, 
        'plt_accuracy1' : True,
        'epochs2' : 40, 
        'plt_accuracy2' : True,
        'epochs3' : 25, 
        'plt_accuracy3' : True,
        'results_array' : True,
        'save_model' : False, 
        'save_model_name' : "models/normalizado_aug_modelv1"
    }

}
\end{lstlisting}

\subsubsection{Secciones}

Las secciones con las que cuenta el \textit{pipeline} son las siguientes:

\begin{enumerate}
    \item \textit{tratar\_dataset\_casia}
    \begin{itemize}
        \item Modificación de la configuración de archivos vista en el Anexo \ref{anx:dataset} a una configuración de directorio único.
    \end{itemize}
    \item \textit{data\_augmentation}
    \begin{itemize}
        \item Aplicación de transformaciones afines.
        \item Aplicación del ruido Gaussiano.
    \end{itemize}
    \item \textit{segmentation}
    \begin{itemize}
        \item Genera las muestras que se le pasaran a la red pre-entrenada.
        \item Segmenta el iris.
    \end{itemize}
    \item \textit{normalization}
    \begin{itemize}
        \item Establece los círculos correspondientes a los bordes del ojo.
        \item Binarización de las imágenes.
        \item Proyección de la sección del iris.
    \end{itemize}
    \item \textit{extraction} (parte del código adaptado, no utilizado en este proyecto).
    \item \textit{clasification} (parte del código adaptado, no utilizado en este proyecto).
    \item \textit{clasificacionCNN}
    \begin{itemize}
        \item Adaptación del conjunto de datos al modelo de entrada de la red neuronal.
        \item División del conjunto de datos para el entrenamiento y el testeo.
        \item Construcción de los tres modelos.
        \item Muestra de resultados y de un ejemplo de clasificación.
    \end{itemize}
\end{enumerate}


\subsubsection{Ejecucción del \textit{pipeline}}

Cada una de las secciones anteriores ha sido encapsulada en una única función, con la configuración del \textit{pipeline} como único parámetro de entrada.
Para ejecutar el \textit{pipeline} se establece cada función dentro de un \textit{FunctionTransformer} y se coloca en el orden requerido dentro de la función \textit{Pipeline}.
Finalmente, se ejecuta el \textit{pipeline}, pasándole la configuración como parámetro.


\begin{lstlisting}[language=Python] 

_1_tratar_dataset_pip = FunctionTransformer(tratar_dataset_casia)
_1_1_data_augmentation_pip = FunctionTransformer(data_augmentation)
_2_1_segmentation_pip = FunctionTransformer(segmentation)
_2_2_normalization_pip = FunctionTransformer(normalization)
_4_clasificationCNN_pip = FunctionTransformer(clasificationCNN)

iris_recognition_pipeline = Pipeline([('_1_tratarDataset', _1_tratar_dataset_pip), 
('_1_1_dataAugmentation', _1_1_data_augmentation_pip), 
('_2_1_segmentation', _2_1_segmentation_pip), 
('_2_2_normalization', _2_2_normalization_pip),
('_3_1_extraction', _3_1_extraction_pip),
('_3_2_clasification', _3_2_clasification_pip), 
('_4_clasificationCNN', _4_clasificationCNN_pip) ])

iris_recognition_pipeline.transform(confi_dict)

\end{lstlisting} 

\subsection{\textit{Notebook} \textit{accuracy.ipynb}} \label{anx:accuracy}

El \textit{notebook} \textit{accuracy.ipynb} permite el cálculo de la tasa de acierto de los modelos, utilizando los modelos creados en el apartado anterior,
así como el conjunto de datos reservado para realizar el testeo.

\subsubsection{Código}

El código del \textit{notebook} está dispuesto de la siguiente forma:

\begin{itemize}
    \item \textit{model}, ruta del modelo a utilizar.
    \item \textit{test\_path\_dir}, ruta del conjunto de datos de testeo.
    \item \textit{size} y \textit{\_parse\_image}, configuración para adaptar la imagen al formato requerido por el modelo.
    \item \textit{realClass\_array}, \textit{array} con la clase real de las imágenes.
    \item \textit{predicted\_array}, \textit{array} con la clase predicha de las imágenes.
    \item \textit{m.update\_state}, obtiene las dos \textit{arrays} anteriores de entrada y determina la tasa de acierto del modelo.
\end{itemize}

\begin{lstlisting}[language=Python] 

model = keras.models.load_model(r"root_folder/models/normalizado_aug_modelv1")
test_path_dir = r'root_folder/CASIA-IrisV1_unif_aug_segv2_edg_norm'
size = (224, 224)

def _parse_image(filename):
    img = tf.io.read_file(filename)
    img = tf.image.decode_bmp(img, channels = 3)
    img = tf.image.resize(img, size)
    img = tf.expand_dims(img, 0)
    return img

paths_array = np.array([x.__str__() for x in pathlib.Path(test_path_dir).rglob('*.bmp')])
realClass_array = np.array([x.split("/")[-1].split("_")[0] for x in paths_array]).astype(int)
predicted_array = np.array([])
for i in paths_array:
    result = model.predict(_parse_image(i))
    predicted_array = np.append(predicted_array, np.argmax(result) + 1)

m = tf.keras.metrics.Accuracy()
m.update_state(realClass_array, predicted_array)
m.result().numpy()

\end{lstlisting}

\section{Compilación, instalación y ejecución del proyecto}

Pasos para la ejecución del proyecto:

\begin{itemize}
    \item Clonar el repositorio del proyecto \url{https://github.com/Ponsoda/tfm-iris-recognition}.
    \item Descargar el conjunto de datos de CASIA-V1. En el proyecto se ha utilizado el conjunto de datos a partir de \url{https://github.com/jaa0124/iris_classifier/tree/master/notebooks/CASIA-IrisV1}.
    \item Abrir el \textit{notebook} \texttt{pipelines.ipynb}.
    \item Determinar la ubicación del conjunto de datos de CASIA-V1 en la configuración del \textit{pipeline}, así como el resto de parámetros y el directorio de salida para los modelos.
    \item Ejecutar todas las celdas del proyecto en el orden definido en el proyecto para la creación de cada uno de los modelos.
    \item Abrir el \textit{notebook} \texttt{accuracy.ipynb}.
    \item Establecer la ubicación del conjunto de datos reservado para el testeo y del modelo a utilizar y lanzar todas las celdas del \textit{notebook}.
\end{itemize}

\section{Pruebas del sistema}

Las diferentes pruebas que se han ido realizando están accesible en el directorio en forma de \textit{notebooks} de Jupyter que pueden ser descargados y ejecutados.
