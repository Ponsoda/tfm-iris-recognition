\capitulo{5}{Aspectos relevantes del desarrollo del proyecto}

El proyecto se divide en una fase preliminar, consistente en la adecuación del código previo, correspondiente en el TFG
el cual se ha hecho extensible en este trabajo y tres propuestas diferentes para la identificación biomédica de personas 
a través de una imagen de su ojo utilizando el iris como parte central de este reconocimiento.

\section{Optimización de los notbooks previos}

La primera fase trata de la optimización del código previo y la creación de un pipeline con una configuración que permitiese un mejor control de las funciones.
Se han creado funciones correspondientes a cada una de las fases y se han encapsulado en forma de partes de una pipeline, con el único argumento de entrada de la 
configuración. 

\imagen{img/03_workflow}{Ejemplo de workflow del paper 05 techniques review}

\subsection{Pipeline y configuración} 

Así pues, esta configuración permite establecer cuales van a ser los parámetros de la pipeline, principalmente (aunque puede ser fácilmente extensible),
 la ubicación del directorio del dataset. el tamaño del dataset de entrenamiento para la creación de los modelos de redes neuronales o los valores
 de data augmentation que se aplican.

\section{Data agumentation}

También del  data augmentation, en el cual se aplica tanto ruido gausseano (de 2.5, 5 y 7.5) como transformaciones afines (mat reflexion, mat scale, rotación y shear), siendo realizadas de 
forma aleatoria, con lo cual los supuestos pueden ser:

\begin{itemize}
    \item Imagen sin data augmentation
    \item Imagen con ruido gausseano
    \item Imagen con transformaciones afines y 
    \item Imagen con ruido gausseano y transformaciones afines. Este dataset será el base para todo el proyecto.
\end{itemize}

Las fases del pipeline anterior, y por lo tanto las funciones creadas en el pipeline son:
1.Tratar el dataset, de forma que las imágenes, distribuidas en distintos directorios, se guardan en uno solo. Posteriormente, se realiza en mezclado de las imágenes, el dataset se divide en dos partes, 
una que será utilizada en el proceso (70 por ciento) y, finalmente, se guarda una parte del dataset que será utilizada para obtener los resultados finales.


La segunda fase se trata de la elección de la mejor forma de clasificar las imagenes de entrada:

\section{Clasificación de las imágenes}

(añadir el tiempo de ejecucción y el acuracy de cada uno de los procesos)

\subsection{Preprocesamiento y Machine Learning}

La propuesta en el TFG anterior, en la cual se realiza un preprocesamiento de las imágenes del dataset original. Este preprocesamiento consiste primer lugar 
en la segmentación de las imágenes del iris con una red neuronal preentrenada precisamente para realizar esta acción. En segundo lugar, se realiza una extracción
del iris a través de una binarización de las partes del ojo y una extracción del iris, a la que se le aplica una normalización para que quede proyectado.
La siguiente fase de esta primera propuesta es la extracción de características (quitandole las dos últimas capas a una red neuronal) de la imagen normalizada
 para posteriormente utilizar una red neuronal preentrenada con imagenet (de hecho 3 redes de la cual se elige la mejor). Posteriormente, estas características
 extraidas se pasan a modelos de ML, que son los que realizarán la clasificación. 

\subsection{Preprocesamiento y Deep Learning}

La segunda propuesta es la utilización de una red neuronal de VGG16, preentrenada con imagenet, a la que se le aplica un fine tunning del dataset de CASIAV1 para
que sea capaz de clasificar las imágenes de acuerdo a las clases establecidas en el dataset.

\subsection{Deep Learning}

La tercera propuesta se basa en la utilización del dataset, directo sin preprocesamiento, para la fase del fine tunning y su posterior clasificación (para la clasificación de imágenes en las fases
que han sufrido preprocesamiento, le deberían de pasar imágenes que primero hayan entrado al pipeline hasta la fase de normalización!!).
(temporal) Los resultados arrojan un acierto mayor en el caso del preproceso + red neuronal, por lo que se puede concluir que, en base a los parámetros establecidos en este estudio, la utilización de 
una fase de preprocesamiento que elimine las partes que los estudios determinan no tan útiles para la clasificación humana (vease, todo aquello que no es parte del iris)
 y posteriormente utiliza el fine tunning para adecuar una red neuronal preentrenada a las clases de las que se compone el dataset.

