{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confi_dict = {\n",
    "\n",
    "    'general':{\n",
    "        'root_dir':r\"/home/ipl1002/root_folder\",\n",
    "        'dataset_dir': \"CASIA-IrisV1\",\n",
    "        'dataset_unif_dir': r\"/home/ipl1002/root_folder/CASIA-IrisV1_unif\",\n",
    "        'dataset_unif_segv2_edg_norm_dir' : r\"/home/ipl1002/root_folder/CASIA-IrisV1_unif_segv2_edg_norm\"\n",
    " \n",
    "    },\n",
    "\n",
    "    '1_tratarDataset':{\n",
    "        'general_train_size': 0.7,\n",
    "        'show_first' : False\n",
    "    },\n",
    "\n",
    "    '1.1_dataAugmentation':{\n",
    "        'gaussianNoise' : True,\n",
    "        'stdGN': [2.5, 5, 7.5],\n",
    "        'afinTransformation': True\n",
    "    },\n",
    "\n",
    "    '2.1_segmentation':{\n",
    "        'redNeuronal' : \"Iris_unet_d5.h5\", \n",
    "        'numSamplesGenerator' : 3, \n",
    "        'verImagenV1' : False\n",
    "    },\n",
    "\n",
    "    '3.1_extraction': {\n",
    "        \n",
    "    },\n",
    "\n",
    "    '4_CNN_classification' :{\n",
    "        'dataset_dir' : \"normalizado\",\n",
    "        'CNN_weights' : \"imagenet\",\n",
    "        'train_size' : 0.7, \n",
    "        'test_size' : 0.3, \n",
    "        'random_seed' : 42, \n",
    "        'batch_size' : 1, \n",
    "        'epochs1' : 50, \n",
    "        'plt_accuracy1' : False,\n",
    "        'epochs2' : 40, \n",
    "        'plt_accuracy2' : False,\n",
    "        'epochs3' : 25, \n",
    "        'plt_accuracy3' : False,\n",
    "        'results_array' : True,\n",
    "        'save_model' : True, \n",
    "        'save_model_name' : \"preprocess_and_nn_model\"\n",
    "    }\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1: Tratar el dataset CASIA\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 tratar_dataset_casia()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tratar_dataset_casia(confi):\n",
    "    \n",
    "    print(\"Función 1, tratar_dataset_casia()\")\n",
    "    \n",
    "    ''' \n",
    "    Importando librerías\n",
    "    '''\n",
    "    try:\n",
    "        import os\n",
    "    except:\n",
    "        !pip install os\n",
    "        import os\n",
    "    try:\n",
    "        import shutil\n",
    "    except:\n",
    "        !pip install shutil\n",
    "        import shutil\n",
    "    try:\n",
    "         import imageio\n",
    "    except:\n",
    "        !pip install imageio\n",
    "        import imageio\n",
    "    try:\n",
    "        import random\n",
    "    except:\n",
    "        !pip install random\n",
    "        import random\n",
    "    try:\n",
    "        import matplotlib.pyplot as plt\n",
    "    except:\n",
    "        !pip install matplotlib\n",
    "        import matplotlib.pyplot as plt\n",
    "    ''' \n",
    "    Estableciendo la root de la función\n",
    "    '''\n",
    "    os.chdir(confi['general']['root_dir'])\n",
    "    \n",
    "    def copy_all_samples(path_samples, destination_directory):\n",
    "        '''\n",
    "        Copia todas las muestras del dataset de CASIA a un único directorio.\n",
    "        '''\n",
    "        if not os.path.exists(path_samples):\n",
    "            print(\"->El directorio indicado como input no existe\")\n",
    "        elif not os.path.exists(destination_directory):\n",
    "            ''' \n",
    "            Comprobamos que el directorio del output no existe\n",
    "            '''\n",
    "            os.mkdir(destination_directory) # Creamos un nuevo directorio \n",
    "            for root, dirs, files in os.walk(path_samples):\n",
    "                for file in files:\n",
    "                    path_file = os.path.join(root,file)\n",
    "                    shutil.copy2(path_file,destination_directory)   \n",
    "            print(\"-> Muestras copiadas satisfactoriamente.\")\n",
    "        elif len(os.listdir(destination_directory)) < 1:\n",
    "            ''' \n",
    "            Comprobamos que el directorio del output no está vacío\n",
    "            '''\n",
    "            for root, dirs, files in os.walk(path_samples):\n",
    "                for file in files:\n",
    "                    path_file = os.path.join(root,file)\n",
    "                    shutil.copy2(path_file,destination_directory)   \n",
    "            print(\"-> Muestras copiadas satisfactoriamente.\")\n",
    "        else:\n",
    "            print(\"-> Muestras previamente copiadas.\")\n",
    "\n",
    "    confi['general']['dataset_unif_dir'] = confi['general']['dataset_dir']+\"_unif\"\n",
    "\n",
    "    copy_all_samples(confi['general']['dataset_dir'], confi['general']['dataset_unif_dir'])\n",
    "\n",
    "    \n",
    "    confi['general']['dataset_reservado_dir'] = confi['general']['dataset_dir']+\"_reservado\"\n",
    "    \n",
    "    if not os.path.exists(confi['general']['dataset_reservado_dir']):\n",
    "        os.mkdir(confi['general']['dataset_reservado_dir'])\n",
    "        dataset_names = os.listdir(confi['general']['dataset_unif_dir'])\n",
    "        dataset_len = len(dataset_names)\n",
    "\n",
    "        random.shuffle(dataset_names)\n",
    "\n",
    "        dataset_apartado = dataset_names[int(dataset_len*confi['1_tratarDataset']['general_train_size']):int(dataset_len)]\n",
    "\n",
    "        for root, dirs, files in os.walk(confi['general']['dataset_unif_dir']):\n",
    "            for i in files:\n",
    "                if i in(dataset_apartado):\n",
    "                    shutil.copy(root + os.sep + i , confi['general']['dataset_reservado_dir'])\n",
    "                    os.remove(root + os.sep + i)\n",
    "\n",
    "\n",
    "    if confi['1_tratarDataset']['show_first']:\n",
    "        ''' \n",
    "        Si en la configuración show_first es True, se mostrará el primer elemento del nuevo directorio.\n",
    "        '''\n",
    "        path_img = confi['general']['dataset_unif_dir'] + os.sep + os.listdir(confi['general']['dataset_unif_dir'])[0]\n",
    "        img = imageio.imread(path_img)\n",
    "        plt.title(\"Primer elemento de \" + confi['general']['dataset_unif_dir'])\n",
    "        plt.imshow(img)\n",
    "    \n",
    "    ''' \n",
    "    Pasando el diccionario con la configuración a la siguiente función\n",
    "    '''\n",
    "    return confi\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 data_augmentation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_augmentation(confi):\n",
    "\n",
    "    print(\"Función 1.1, data_augmentation()\")\n",
    "    \n",
    "    ''' \n",
    "    Importando librerías\n",
    "    '''\n",
    "    try:\n",
    "        import os\n",
    "    except:\n",
    "        !pip install os\n",
    "        import os\n",
    "    try:\n",
    "        import imageio\n",
    "    except:\n",
    "        !pip install imageio\n",
    "        import imageio\n",
    "    try:\n",
    "        import skimage.io as io\n",
    "        from skimage.io import imread\n",
    "        from skimage.color import rgb2gray\n",
    "    except:\n",
    "        !pip install scikit-image\n",
    "        import skimage.io as io\n",
    "        from skimage.io import imread\n",
    "        from skimage.color import rgb2gray\n",
    "    try:\n",
    "        import matplotlib.pyplot as plt\n",
    "    except:\n",
    "        !pip install matplotlib\n",
    "        import matplotlib.pyplot as plt\n",
    "    try:\n",
    "        from tensorflow.keras.layers import GaussianNoise\n",
    "    except:\n",
    "        !pip install tensorflow\n",
    "        from tensorflow.keras.layers import GaussianNoise\n",
    "    try:\n",
    "        import numpy as np\n",
    "    except:\n",
    "        !pip install numpy\n",
    "        import numpy as np\n",
    "    try:\n",
    "        import random\n",
    "    except:\n",
    "        !pip install random\n",
    "        import random\n",
    "    try:\n",
    "        from scipy import ndimage as ndi\n",
    "    except:\n",
    "        !pip install scipy\n",
    "        from scipy import ndimage as ndi\n",
    "\n",
    "    def affine_transformation(image, trans_type):\n",
    "        if trans_type == 0:\n",
    "            mat_reflect = np.array([[1,0,0],[0,-1,0],[0,0,1]]) @ np.array([[1,0,0],[0,1,-h],[0,0,1]])\n",
    "            image = ndi.affine_transform(image, mat_reflect)\n",
    "        elif trans_type == 1:\n",
    "            s_x, s_y = 0.95, 1.05\n",
    "            mat_scale = np.array([[s_x,0,0],[0,s_y,0],[0,0,1]])\n",
    "            image = ndi.affine_transform(image, mat_scale)\n",
    "        elif trans_type == 2:\n",
    "            mat_identity = np.array([[1,0,0],[0,1,0],[0,0,1]])\n",
    "            img1 = ndi.affine_transform(image, mat_identity)\n",
    "            theta = np.pi/10\n",
    "            mat_rotate = np.array([[1,0,w/2],[0,1,h/2],[0,0,1]]) @ np.array([[np.cos(theta),np.sin(theta),0],[np.sin(theta),-np.cos(theta),0],[0,0,1]]) @ np.array([[1,0,-w/2],[0,1,-h/2],[0,0,1]])\n",
    "            image = ndi.affine_transform(img1, mat_rotate)\n",
    "        elif trans_type == 3:\n",
    "            mat_identity = np.array([[1,0,0],[0,1,0],[0,0,1]])\n",
    "            img1 = ndi.affine_transform(image, mat_identity)\n",
    "            lambda1 = 0.1\n",
    "            mat_shear = np.array([[1,lambda1,0],[lambda1,1,0],[0,0,1]])\n",
    "            image = ndi.affine_transform(img1, mat_shear)\n",
    "        else:\n",
    "            print(\"Invalid affine transformation type\")\n",
    "        \n",
    "        return image\n",
    "\n",
    "    ''' \n",
    "    Estableciendo la root de la función\n",
    "    '''\n",
    "    os.chdir(confi['general']['root_dir'])\n",
    "    \n",
    "    ''' \n",
    "    Comprobamos si el ruido gaussiano ha sido establecido como True en la configuración\n",
    "    '''     \n",
    "    if confi['1.1_dataAugmentation']['gaussianNoise']:\n",
    "\n",
    "        ''' \n",
    "        Desde el directorio unificado creamos nuevas imágenes utilizando el ruido gaussiano como data augmentation.\n",
    "        Si el random es 0, no se aplica el aumentador, en cambio si es 1 sí se aplica.\n",
    "        '''\n",
    "        for filename in os.listdir(confi['general']['dataset_unif_dir']):\n",
    "            if \".bmp\" in filename:\n",
    "                if random.randint(0, 1) == 1:\n",
    "                    path = confi['general']['dataset_unif_dir'] + os.sep + filename\n",
    "                    image = imageio.imread(path)/255\n",
    "                    std_rdm = random.choice(confi['1.1_dataAugmentation']['stdGN'])\n",
    "                    gaussean_function = GaussianNoise(std_rdm/100)\n",
    "                    noisey = gaussean_function(image.astype(np.float32),training=True)\n",
    "                    name = path[:-4] + '_noise.bmp'\n",
    "                    io.imsave(name, noisey)\n",
    "        print(\"->Data augmentation 'ruido gausseano' ejecutado correctamente\")\n",
    "    else:\n",
    "        print(\"->Saltando el ruido gausseano en data augmentation\")\n",
    "\n",
    "    ''' \n",
    "    Comprobamos si las transformaciones afines ha aplicado anteriormente, si es así, el primer elemento del directorio debería de tener el sufijo _augmentation\n",
    "    '''\n",
    "    if confi['1.1_dataAugmentation']['afinTransformation']:\n",
    "        ''' \n",
    "        Desde el directorio unificado creamos nuevas imágenes utilizando el ruido gaussiano como data augmentation.\n",
    "        Si el random es 0, no se aplica el aumentador, en cambio si es 1 sí se aplica.\n",
    "        '''\n",
    "        i = 0\n",
    "        for filename in os.listdir(confi['general']['dataset_unif_dir']):\n",
    "            if \".bmp\" in filename:\n",
    "                if random.randint(0, 1) == 1:\n",
    "                    path = confi['general']['dataset_unif_dir'] + os.sep + filename\n",
    "                    image = rgb2gray(imread(path))\n",
    "                    w, h = image.shape\n",
    "                    transformation_type = random.randint(0, 3)\n",
    "                    image = affine_transformation(image, transformation_type)\n",
    "                    name = path[:-4] + '_affine.bmp'\n",
    "                    io.imsave(name, image)\n",
    "        print(\"->Data augmentation 'transformación afin' ejecutado correctamente\")\n",
    "    else:\n",
    "        print(\"->Saltando las transformaciones afines en data augmentation\")\n",
    "\n",
    "    ''' \n",
    "    Pasando el diccionario con la configuración a la siguiente función\n",
    "    '''\n",
    "    return confi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Red U-Net v2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 segmentation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segmentation(confi):\n",
    "\n",
    "    print(\"Función 2.1, segmentation()\")\n",
    "\n",
    "    ''' \n",
    "    Importando librerías\n",
    "    '''\n",
    "    try:\n",
    "        import os\n",
    "    except:\n",
    "        !pip install os\n",
    "        import os\n",
    "    try:\n",
    "        import cv2\n",
    "    except:\n",
    "        !pip install opencv-python\n",
    "        import cv2\n",
    "    try:\n",
    "        import shutil\n",
    "    except:\n",
    "        !pip install shutil\n",
    "        import shutil\n",
    "    try:\n",
    "         import imageio\n",
    "    except:\n",
    "        !pip install imageio\n",
    "        import imageio\n",
    "    try:\n",
    "        import skimage.transform as trans\n",
    "        from skimage.io import imshow\n",
    "        import skimage.io as io\n",
    "    except:\n",
    "        !pip install scikit-image\n",
    "        import skimage.transform as trans\n",
    "        from skimage.io import imshow\n",
    "        import skimage.io as io\n",
    "    try:\n",
    "        import matplotlib.pyplot as plt\n",
    "    except:\n",
    "        !pip install matplotlib\n",
    "        import matplotlib.pyplot as plt\n",
    "    try:\n",
    "        from keras.models import load_model\n",
    "    except:\n",
    "        !pip install tensorflow \n",
    "        from keras.models import load_model\n",
    "    try:\n",
    "        import numpy as np\n",
    "    except:\n",
    "        !pip install numpy\n",
    "        import numpy as np\n",
    "    try:\n",
    "        from PIL import Image\n",
    "    except:\n",
    "        !pip install Pillow\n",
    "        from PIL import Image\n",
    "    ''' \n",
    "    Estableciendo la root de la función\n",
    "    '''\n",
    "    os.chdir(confi['general']['root_dir'])\n",
    "\n",
    "    ''' \n",
    "    Creamos un generador con un número n de imágenes para pasarselas al modelo en el predict\n",
    "    *Recordemos que este modelo ya está entrenado para la segmentación del ojo\n",
    "    '''\n",
    "    def testGenerator(directory, target_size = (320,320)):\n",
    "        '''\n",
    "        Genera las muestras que se le pasarán al método predecir de la red preentrenada.\n",
    "        \n",
    "        Parámetros:\n",
    "        directory -- directorio dónde se encuentran las muestras a generar\n",
    "        num_image -- número máximo de imágenes que queremos generar\n",
    "        target_size -- shape de de la muestra\n",
    "        flag_multi_class -- (de momento mantener pero no nos es útil)\n",
    "        '''\n",
    "        for file in os.listdir(directory):\n",
    "            if \".bmp\" in file:\n",
    "                path_file = os.path.join(directory,file)\n",
    "                print(path_file)\n",
    "                img = imageio.imread(path_file)\n",
    "                img = img / 255\n",
    "                img = trans.resize(img,target_size)\n",
    "                img = np.reshape(img, img.shape+(1,))\n",
    "                img = np.reshape(img, (1,) + img.shape)\n",
    "                yield img\n",
    "    \n",
    "    def get_samples_names(directory):\n",
    "        '''\n",
    "        Devuelve los nombres de las muestras (los que se encuentran en los directorios hoja)\n",
    "        \n",
    "        Parámetros:\n",
    "        directory -- directorio de cuyos subdirectorios hoja se quiere el nombre \n",
    "        '''\n",
    "        names = []\n",
    "        for file in os.listdir(directory):\n",
    "            if \".bmp\" in file:\n",
    "                names.append(str(file))\n",
    "                \n",
    "        return names\n",
    "\n",
    "    def saveResult(save_path, name_path, npyfile):\n",
    "        '''\n",
    "        Guarda los imágenes segmentadas resultado de la red preentrenada\n",
    "        \n",
    "        Parámetros:\n",
    "        save_path -- ruta en la que se guardarán las muestras segmentadas\n",
    "        name_path -- directorio del que cogeremos los nombres de las muestras\n",
    "        npyfile -- resultado de la red preentrenada\n",
    "        '''\n",
    "        dim = (320, 280) # dimensioned de las muestras del dataset\n",
    "        os.mkdir(save_path)\n",
    "        names = get_samples_names(name_path)\n",
    "        for i, item in enumerate(npyfile):\n",
    "            img = item[:,:,0]\n",
    "            img = cv2.resize(img, dim, interpolation=cv2.INTER_AREA)\n",
    "            io.imsave(os.path.join(save_path,names[i]),img)    \n",
    "\n",
    "    confi['general']['dataset_unif_seg_dir'] =  confi['general']['dataset_unif_dir']  + \"_seg\"\n",
    "    if not os.path.exists(confi['general']['dataset_unif_seg_dir']):\n",
    "        ''' \n",
    "        Cargamos el modelo de segmentación\n",
    "        '''\n",
    "        model = load_model(confi['2.1_segmentation']['redNeuronal'])\n",
    "        print(\"->Modelo cargado\")\n",
    "        testGene = testGenerator(confi['general']['dataset_unif_dir'])\n",
    "        Unet_results = model.predict(testGene, verbose=1) \n",
    "        saveResult(confi['general']['dataset_unif_seg_dir'], confi['general']['dataset_unif_dir'], Unet_results)\n",
    "        print(\"->Segmentaciones guardadas\")\n",
    "    else:\n",
    "        print(\"->Segmentaciones previamente guardadas\")\n",
    "\n",
    "    if confi['2.1_segmentation']['verImagenV1']:\n",
    "        sample = \"001_1_1.bmp\"\n",
    "        path_img = confi['general']['dataset_unif_dir'] + os.sep + sample\n",
    "        path_back = confi['general']['dataset_unif_seg_dir'] + os.sep + sample\n",
    "        image = Image.open(path_img)\n",
    "        background = Image.open(path_back)\n",
    "        background.paste(image, (0, 0), image)\n",
    "        plt.imshow(background, cmap='gray');\n",
    "    \n",
    "    confi['general']['dataset_unif_segv2_dir'] = confi['general']['dataset_unif_seg_dir'] + \"v2\"\n",
    "    confi['general']['dataset_unif_segv2_edg_dir'] = confi['general']['dataset_unif_segv2_dir'] + \"_edg\"\n",
    "\n",
    "    segv2_dir = False\n",
    "    edge_dir = False\n",
    "\n",
    "    for file in os.listdir(confi['general']['dataset_unif_seg_dir']):\n",
    "        if \".bmp\" in file:\n",
    "            path_file = os.path.join(confi['general']['dataset_unif_seg_dir'],file)\n",
    "            img = cv2.imread(path_file)\n",
    "            blur= cv2.GaussianBlur(img,(17,17),0)\n",
    "            (thresh, binarized) = cv2.threshold(blur, 70, 255, cv2.THRESH_BINARY) # se binariza nuevamente\n",
    "            edges = cv2.Canny(binarized, 10, 255)\n",
    "\n",
    "            # creamos un nuevo directorio para guardar las muestras segmentadas con mayor calidad\n",
    "            if not os.path.exists(confi['general']['dataset_unif_segv2_dir']):\n",
    "                os.mkdir(confi['general']['dataset_unif_segv2_dir'])\n",
    "                cv2.imwrite(confi['general']['dataset_unif_segv2_dir'] + os.sep + file, binarized)\n",
    "                segv2_dir = True\n",
    "            elif segv2_dir:\n",
    "                cv2.imwrite(confi['general']['dataset_unif_segv2_dir'] + os.sep + file, binarized)\n",
    "            else:\n",
    "                print(\"->La segmentación v2 ya había sido creada\")\n",
    "                break \n",
    "\n",
    "            # creamos un nuevo directorio para guardar las muestras con los bordes detectados\n",
    "            if not os.path.exists(confi['general']['dataset_unif_segv2_edg_dir']):\n",
    "                os.mkdir(confi['general']['dataset_unif_segv2_edg_dir'])\n",
    "                cv2.imwrite(confi['general']['dataset_unif_segv2_edg_dir'] + os.sep + file, edges)# guardamos muestra\n",
    "                edge_dir = True\n",
    "            elif edge_dir:\n",
    "                cv2.imwrite(confi['general']['dataset_unif_segv2_edg_dir'] + os.sep + file, edges)# guardamos muestra\n",
    "            else:\n",
    "                print(\"->La edge ya había sido creada\")\n",
    "                break \n",
    "    \n",
    "    print(\"->Segmentaciones V2 guardadas\")\n",
    "    print(\"->Edge guardadas\")\n",
    "\n",
    "    return confi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 normalization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalization(confi):\n",
    "\n",
    "    print(\"Función 2.2, normalization()\")\n",
    "\n",
    "    ''' \n",
    "    Importando librerías\n",
    "    '''\n",
    "    try:\n",
    "        import os\n",
    "    except:\n",
    "        !pip install os\n",
    "        import os\n",
    "    try:\n",
    "        import cv2\n",
    "    except:\n",
    "        !pip install opencv-python\n",
    "        import cv2\n",
    "    try:\n",
    "        from skimage.transform import (hough_circle, hough_circle_peaks)\n",
    "        from skimage.io import imshow\n",
    "    except:\n",
    "        !pip install scikit-image\n",
    "        from skimage.transform import (hough_circle, hough_circle_peaks)\n",
    "        from skimage.io import imshow\n",
    "    try:\n",
    "         import imageio\n",
    "    except:\n",
    "        !pip install imageio\n",
    "        import imageio\n",
    "    try:\n",
    "        import numpy as np\n",
    "    except:\n",
    "        !pip install numpy\n",
    "        import numpy as np\n",
    "    try:\n",
    "        import matplotlib.pyplot as plt\n",
    "    except:\n",
    "        !pip install matplotlib\n",
    "        import matplotlib.pyplot as plt\n",
    "    try:\n",
    "        import pandas as pd\n",
    "    except:\n",
    "        !pip install pandas\n",
    "        import pandas as pd\n",
    "    ''' \n",
    "    Estableciendo la root de la función\n",
    "    '''\n",
    "    os.chdir(confi['general']['root_dir'])\n",
    "    ''' \n",
    "    Creando funciones\n",
    "    '''\n",
    "\n",
    "    def draw_circles(img, cx, cy, radii):\n",
    "        '''\n",
    "        A partir de los centros y el radio detectados dibuja el iris sobre la imagen que se le\n",
    "        pasa como parámetro.\n",
    "        '''\n",
    "        image = img.copy()\n",
    "        return image\n",
    "    \n",
    "    def get_circles(borde, sample):\n",
    "        path_edged = confi['general']['dataset_unif_segv2_edg_dir'] + os.sep + sample\n",
    "        gray_img = imageio.imread(path_edged)\n",
    "        \n",
    "        hough_radii = np.arange(20, 80) # pupila por defecto\n",
    "        if borde == \"iris\":\n",
    "            hough_radii = np.arange(90, 160) # rango del iris\n",
    "        \n",
    "        hough_res = hough_circle(gray_img, hough_radii)\n",
    "        accums, cx, cy, radii = hough_circle_peaks(hough_res, hough_radii, total_num_peaks=1) \n",
    "\n",
    "        return [cx[0], cy[0], radii[0]]\n",
    "\n",
    "    confi['general']['dataset_unif_segv2_edg_norm_dir'] = confi['general']['dataset_unif_segv2_edg_dir'] + \"_norm\"\n",
    "    \n",
    "    if not os.path.exists(confi['general']['dataset_unif_segv2_edg_norm_dir']):\n",
    "        \n",
    "        os.mkdir(confi['general']['dataset_unif_segv2_edg_norm_dir'])\n",
    "    \n",
    "        image_files = []\n",
    "        new_dir = confi['general']['dataset_unif_segv2_edg_dir']\n",
    "\n",
    "        for root, dirs, files in os.walk(new_dir):\n",
    "            for file in files:\n",
    "                if file.endswith(\".bmp\"):\n",
    "                    image_files.append(file)\n",
    "                    \n",
    "        # cogemos las clases a las que pertenece cada .bmp\n",
    "        classes = []\n",
    "        images_names= [] \n",
    "        \n",
    "        x_pupil, y_pupil, r_pupil =[], [], []\n",
    "        x_iris, y_iris, r_iris =[],[],[]\n",
    "\n",
    "        for file in os.listdir(confi['general']['dataset_unif_segv2_dir']):\n",
    "\n",
    "            path_sample = confi['general']['dataset_unif_dir'] + os.sep + file\n",
    "            sample_image = imageio.imread(path_sample)\n",
    "            boundaries,centers, pupil_centers = [],[],[]\n",
    "            \n",
    "            try:\n",
    "                pupil_coord = get_circles(\"pupil\",file)\n",
    "                \n",
    "                # 30 como tamaño minimo para mantener buena calidad\n",
    "                if pupil_coord[2] > 30:\n",
    "\n",
    "                    iris_coord = get_circles(\"iris\",file)\n",
    "\n",
    "                    cx, cy, radius = list(zip(pupil_coord, iris_coord))\n",
    "                    draw = draw_circles(sample_image,cx,cy,radius)\n",
    "\n",
    "                    boundaries.append(draw)\n",
    "                    data = {'pupil':pupil_coord,\n",
    "                            'iris':iris_coord}\n",
    "\n",
    "                    centers.append(data)\n",
    "                    pupil_centers.append(pupil_coord)\n",
    "\n",
    "                    target = [img for img in boundaries]\n",
    "\n",
    "                    normalized=[]\n",
    "                    cent=0\n",
    "                        \n",
    "                    for img in target:\n",
    "                        #load pupil centers and radius of inner circles\n",
    "                        center_x = pupil_centers[cent][0]\n",
    "                        center_y = pupil_centers[cent][1]\n",
    "                        radius_pupil=int(pupil_centers[cent][2])\n",
    "\n",
    "                        iris_radius = 53 # width of space between inner and outer boundary\n",
    "\n",
    "                        #define equally spaced interval to iterate over\n",
    "                        nsamples = 360\n",
    "                        samples = np.linspace(0,2*np.pi, nsamples)[:-1]\n",
    "                        polar = np.zeros((iris_radius, nsamples))\n",
    "                        for r in range(iris_radius):\n",
    "                            for theta in samples:\n",
    "                                #get x and y for values on inner boundary\n",
    "                                x = (r+radius_pupil)*np.cos(theta)+center_x\n",
    "                                y = (r+radius_pupil)*np.sin(theta)+center_y\n",
    "                                x=int(x)\n",
    "                                y=int(y)\n",
    "                                try:\n",
    "                                    #convert coordinates\n",
    "                                    polar[r][int((theta*nsamples)/(2*np.pi))] = img[y][x]\n",
    "                                except IndexError: #ignores values which lie out of bounds\n",
    "                                    pass\n",
    "                                continue\n",
    "                        res = cv2.resize(polar,(512,64))\n",
    "                        normalized.append(res)\n",
    "                        cent+=1\n",
    "\n",
    "                    h,w = normalized[0].shape # height, width\n",
    "\n",
    "                    roi = normalized[0][10:h, 0:int(512/2)]\n",
    "                    roi = roi.astype(np.uint8) \n",
    "                    roi_enhanced = cv2.equalizeHist(roi)\n",
    "                    cv2.imwrite(confi['general']['dataset_unif_segv2_edg_norm_dir'] + os.sep + file, roi_enhanced)\n",
    "\n",
    "                    classes.append(file.split('_', 1)[0])\n",
    "                    images_names.append(file)\n",
    "                    for i in centers:\n",
    "                        x_pupil.append(i['pupil'][0])\n",
    "                        y_pupil.append(i['pupil'][1])\n",
    "                        r_pupil.append(i['pupil'][2])\n",
    "                        x_iris.append(i['iris'][0])\n",
    "                        y_iris.append(i['iris'][1])\n",
    "                        r_iris.append(i['iris'][2])\n",
    "                else:\n",
    "                    print(f\"No se pudo extraer el iris de: {file}\")\n",
    "            except:\n",
    "                print(f\"No se pudo extraer el iris de: {file}\")\n",
    "\n",
    "        print(classes)\n",
    "        data = {'image': images_names,\n",
    "        'pupil x_center':x_pupil,\n",
    "        'pupil y_center':y_pupil,\n",
    "        'pupil radius': r_pupil,\n",
    "        'iris x_center': x_iris,\n",
    "        'iris y_center': y_iris,\n",
    "        'iris radius':r_iris,\n",
    "        'class': classes}\n",
    "        \n",
    "        ################################# arrays must be the same lenght\n",
    "        df = pd.DataFrame(data)[['image','pupil x_center','pupil y_center','pupil radius','iris x_center', 'iris y_center','iris radius',\"class\"]] \n",
    "\n",
    "        df.to_csv(\"iris_data.csv\")\n",
    "    \n",
    "    else:\n",
    "        print(\"->Normalización realizada con anterioridad\")\n",
    "\n",
    "    return confi\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Feature extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 extraction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extraction(confi):\n",
    "    \n",
    "    print(\"Función 3.1, extraction()\")\n",
    "\n",
    "    ''' \n",
    "    Importando librerías\n",
    "    '''\n",
    "    try:\n",
    "        import os\n",
    "    except:\n",
    "        !pip install os\n",
    "        import os\n",
    "    try:\n",
    "        import cv2\n",
    "    except:\n",
    "        !pip install opencv-python\n",
    "        import cv2\n",
    "    try:\n",
    "        from keras.applications.vgg16 import VGG16\n",
    "        from keras.applications.inception_v3 import InceptionV3\n",
    "        from keras.applications.resnet_v2 import ResNet50V2\n",
    "        from keras.applications.vgg16 import preprocess_input as vgg16_preprocessor\n",
    "        from keras.applications.inception_v3 import preprocess_input as inception_v3_preprocessor\n",
    "        from keras.applications.resnet_v2 import preprocess_input as resnet_v2_preprocessor\n",
    "        from keras.models import clone_model\n",
    "        from keras.models import Model\n",
    "        from keras.preprocessing import image\n",
    "    except:\n",
    "        !pip install keras\n",
    "        from keras.applications.vgg16 import VGG16\n",
    "        from keras.applications.inception_v3 import InceptionV3\n",
    "        from keras.applications.resnet_v2 import ResNet50V2\n",
    "        from keras.applications.vgg16 import preprocess_input as vgg16_preprocessor\n",
    "        from keras.applications.inception_v3 import preprocess_input as inception_v3_preprocessor\n",
    "        from keras.applications.resnet_v2 import preprocess_input as resnet_v2_preprocessor\n",
    "        from keras.models import clone_model\n",
    "        from keras.models import Model\n",
    "        from keras.preprocessing import image\n",
    "    try:\n",
    "        from IPython.display import clear_output\n",
    "    except:\n",
    "        !pip install ipython\n",
    "        from IPython.display import clear_output\n",
    "    try:\n",
    "        import numpy as np\n",
    "    except:\n",
    "        !pip install numpy\n",
    "        import numpy as np\n",
    "    try:\n",
    "        import matplotlib.pyplot as plt\n",
    "    except:\n",
    "        !pip install matplotlib\n",
    "        import matplotlib.pyplot as plt\n",
    "    try:\n",
    "        import pandas as pd\n",
    "    except:\n",
    "        !pip install pandas\n",
    "        import pandas as pd\n",
    "\n",
    "    ''' \n",
    "    Estableciendo la root de la función\n",
    "    '''\n",
    "    os.chdir(confi['general']['root_dir'])\n",
    "    ''' \n",
    "    Creando funciones\n",
    "    '''\n",
    "    models_dict = {}\n",
    "    vgg16_dict, inception_v3_dict, resnet50_dict = {} ,{} ,{}\n",
    "\n",
    "    # if there a way to check if they are already load??\n",
    "    #\n",
    "    #\n",
    "    #\n",
    "    print(\"Loading VGG16\")\n",
    "    model = VGG16(weights='imagenet')\n",
    "    model = Model(model.input, model.layers[-2].output) # output_shape de la penúltima capa(fully-connected) -> (,4096)\n",
    "    vgg16_dict[\"model\"] = clone_model(model)\n",
    "    vgg16_dict[\"preprocesor\"] = vgg16_preprocessor\n",
    "    vgg16_dict[\"target_size\"] = model.input_shape[1], model.input_shape[2]# default vgg16 input (224,224)\n",
    "\n",
    "\n",
    "    print(\"Loading Inception v3\")\n",
    "    model = InceptionV3(weights='imagenet')\n",
    "    model = Model(model.input, model.layers[-2].output)# output_shape de la penúltima capa(pooling) -> (,2048)\n",
    "    inception_v3_dict[\"model\"] = clone_model(model)\n",
    "    inception_v3_dict[\"preprocesor\"] = inception_v3_preprocessor\n",
    "    inception_v3_dict[\"target_size\"] = model.input_shape[1],model.input_shape[2] # default inceptionv3 input (299,299)\n",
    "\n",
    "\n",
    "    print(\"Loading ResNet 50\")\n",
    "    model = ResNet50V2(weights='imagenet')\n",
    "    model = Model(model.input, model.layers[-2].output)# output_shape de la penúltima capa(pooling) -> (,2048)\n",
    "    resnet50_dict[\"model\"] = clone_model(model)\n",
    "    resnet50_dict[\"preprocesor\"] = resnet_v2_preprocessor\n",
    "    resnet50_dict[\"target_size\"] = model.input_shape[1],model.input_shape[2]# default ResNet input (224,224)\n",
    "\n",
    "\n",
    "    # diccionarios de los 3 modelos, clave -> nombre, valor -> otro diccionario\n",
    "    models_dict[\"VGG16\"] = vgg16_dict\n",
    "    models_dict[\"InceptionV3\"] = inception_v3_dict\n",
    "    models_dict[\"ResNet50\"] = resnet50_dict\n",
    "\n",
    "\n",
    "    confi['3.1_extraction']['models_dict'] = models_dict\n",
    "\n",
    "    clear_output()\n",
    "\n",
    "    ''' \n",
    "    Extract features: extracción de features pasandole una imágen y el modelo a utilizar\n",
    "    '''\n",
    "    def extract_features(image_path, model_name):\n",
    "        '''\n",
    "        model_name extaerá los features de la imagen que se le pase como parámetro.\n",
    "        '''\n",
    "        model_dict = models_dict[model_name]\n",
    "        ####\n",
    "        model = model_dict[\"model\"]\n",
    "        preprocessor = model_dict[\"preprocesor\"]\n",
    "        target_size = model_dict[\"target_size\"]\n",
    "        # se carga la imagen y después se ajusta al input shape del modelo\n",
    "        img = cv2.resize(cv2.imread(image_path),target_size)\n",
    "\n",
    "        img_data = image.img_to_array(img)\n",
    "        img_data = np.expand_dims(img_data, axis=0)\n",
    "        img_data = preprocessor(img_data)\n",
    "        \n",
    "        # extracción de features\n",
    "        features = model.predict(img_data)\n",
    "        return features[0]\n",
    "\n",
    "    # cargamos csv con los datos de las muestras\n",
    "    df = pd.read_csv(\"iris_data.csv\", dtype={'class': str}, index_col=0) # quitamos columna unnamed\n",
    "\n",
    "    # cambiamos nombre de columnas para evitar conflictos con palabras reservadas de Pytho\n",
    "    df.rename(columns={'image':'Image','class':'Clase'}, inplace=True)\n",
    "\n",
    "    def register_to_deepfeatures(register):\n",
    "        \"\"\"\n",
    "        Compute all CNN features    \n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        register : Series\n",
    "            Serie containing metadata of the image\n",
    "    \n",
    "        Returns\n",
    "        -------\n",
    "        results : Series \n",
    "            A Pandas Serie contanining all of the features\n",
    "\n",
    "        \"\"\"\n",
    "        img_name = register.Image # nombre de la muestra e.g: Rafael_1.bmp\n",
    "        clase = register.Clase # clase e.g Rafael\n",
    "\n",
    "        img_dir = os.path.join(confi['general']['dataset_unif_segv2_edg_norm_dir'], img_name)\n",
    "\n",
    "        basic_values = pd.Series([img_name,clase],[\"Name\",\"Class\"])\n",
    "\n",
    "        all_features = []\n",
    "        all_names = []\n",
    "        models = models_dict.keys() # 3 modelos\n",
    "        \n",
    "        for model in models:\n",
    "            features = extract_features(img_dir, model)\n",
    "            names = [f\"{model}_{i}\" for i in range(len(features))]\n",
    "            all_features+=list(features)\n",
    "            all_names+= names\n",
    "            \n",
    "        results = pd.Series(all_features,all_names)\n",
    "        return pd.concat((basic_values,results))\n",
    "\n",
    "    # aplica la función a todas las FILAS del dataframe(parecido a map())\n",
    "    df_deep = df.apply(register_to_deepfeatures, axis=1)\n",
    "    df_deep.to_csv(\"iris_deep_features.csv\")\n",
    "\n",
    "    print(\"End extraction\")\n",
    "\n",
    "    return confi\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 clasification()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clasification(confi):\n",
    "    \n",
    "    print(\"Función 3.2, clasification()\")\n",
    "\n",
    "    ''' \n",
    "    Importando librerías\n",
    "    '''\n",
    "\n",
    "    try:\n",
    "        import cv2\n",
    "    except:\n",
    "        !pip install opencv-python\n",
    "        import cv2\n",
    "    try:\n",
    "        import pickle\n",
    "    except:\n",
    "        !pip install pickle-mixin\n",
    "        import pickle\n",
    "    try:\n",
    "        from sklearn.pipeline import make_pipeline\n",
    "        from sklearn.preprocessing import StandardScaler\n",
    "        from sklearn.model_selection import cross_val_predict\n",
    "        from sklearn.svm import  SVC\n",
    "        from sklearn.neighbors import KNeighborsClassifier\n",
    "        from sklearn.linear_model import LogisticRegression\n",
    "        from sklearn.ensemble import RandomForestClassifier\n",
    "        from sklearn.metrics import classification_report\n",
    "        from sklearn.metrics import accuracy_score\n",
    "        from sklearn.metrics import confusion_matrix\n",
    "        from sklearn.model_selection import train_test_split\n",
    "    except:\n",
    "        !pip install -U scikit-learn\n",
    "        from sklearn.pipeline import make_pipeline\n",
    "        from sklearn.preprocessing import StandardScaler\n",
    "        from sklearn.model_selection import cross_val_predict\n",
    "        from sklearn.svm import  SVC\n",
    "        from sklearn.neighbors import KNeighborsClassifier\n",
    "        from sklearn.linear_model import LogisticRegression\n",
    "        from sklearn.ensemble import RandomForestClassifier\n",
    "        from sklearn.metrics import classification_report\n",
    "        from sklearn.metrics import accuracy_score\n",
    "        from sklearn.metrics import confusion_matrix\n",
    "        from sklearn.model_selection import train_test_split\n",
    "    try:\n",
    "        from keras.preprocessing import image\n",
    "    except:\n",
    "        !pip install keras\n",
    "        from keras.preprocessing import image\n",
    "    import winsound\n",
    "    try:\n",
    "        from tqdm import tqdm\n",
    "    except:\n",
    "        !pip install tqdm\n",
    "        from tqdm import tqdm\n",
    "    try:\n",
    "        from joblib import dump, load\n",
    "    except:\n",
    "        !pip install joblib\n",
    "        from joblib import dump, load\n",
    "    try:\n",
    "        import heapq\n",
    "    except:\n",
    "        !pip install heapq\n",
    "        import heapq\n",
    "    try:\n",
    "        import numpy as np\n",
    "    except:\n",
    "        !pip install numpy\n",
    "        import numpy as np\n",
    "    try:\n",
    "        import matplotlib.pyplot as plt\n",
    "    except:\n",
    "        !pip install matplotlib\n",
    "        import matplotlib.pyplot as plt\n",
    "    try:\n",
    "        import pandas as pd\n",
    "    except:\n",
    "        !pip install pandas\n",
    "        import pandas as pd\n",
    "\n",
    "    ''' \n",
    "    Elegir el estimador correcto\n",
    "    '''\n",
    "\n",
    "    data = pd.read_csv(\"iris_deep_features.csv\", dtype={'Class': str}, index_col=0)\n",
    "\n",
    "    pretrained_models = [\"VGG16\",\"InceptionV3\",\"ResNet50\"]\n",
    "    # true labels\n",
    "    y = data.Class.values\n",
    "\n",
    "\n",
    "    vgg_cols = data.columns.str.startswith(\"VGG16\")\n",
    "    inception_cols = data.columns.str.startswith(\"InceptionV3\")\n",
    "    resnet_cols = data.columns.str.startswith(\"ResNet50\")\n",
    "\n",
    "\n",
    "    vgg_X = data[data.columns[vgg_cols]].values\n",
    "    inception_X = data[data.columns[inception_cols]].values\n",
    "    resnet_X = data[data.columns[resnet_cols]].values\n",
    "\n",
    "\n",
    "    datasets = [(vgg_X,y), (inception_X,y), (resnet_X,y)]\n",
    "    datasets_names = pretrained_models.copy()\n",
    "\n",
    "    '''\n",
    "    List of classifiers and their names included in the experimental study\n",
    "    '''\n",
    "\n",
    "    cls_names = [\"SVM\", \"Nearest Neighbors\", \"LogisticRegression\", \"Random Forest\"] #\"Gradient Boosting Trees\"]\n",
    "\n",
    "    classifiers = [ make_pipeline(StandardScaler(), SVC(kernel='linear')), #(StandardScaler(), grid_svm)\n",
    "                    make_pipeline(StandardScaler(), KNeighborsClassifier(3)),\n",
    "                    make_pipeline(StandardScaler(), LogisticRegression(max_iter=1000)),\n",
    "                    RandomForestClassifier(random_state=0, n_estimators=100),\n",
    "    #                 GradientBoostingClassifier(random_state=0, n_estimators=100)\n",
    "                    ]\n",
    "\n",
    "\n",
    "    def cross_validate_preds_model(X, y, model, num_folds):\n",
    "        '''\n",
    "        @author José F. Díez Pastor\n",
    "        Perform cross validation with a model and a dataset (X and y),\n",
    "        and returns the predictions to later obtain the measurements \n",
    "        you want\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X: numpy.array\n",
    "            Dataset (features)\n",
    "        Y: numpy.array\n",
    "            Dataset (Target)\n",
    "        model: scikit_model\n",
    "            model to be trained\n",
    "        num_folds: int\n",
    "            number of folds in the cross validation\n",
    "        \n",
    "        Return\n",
    "        -------\n",
    "        array \n",
    "            array of prediccions obtained using cross_validation\n",
    "        '''\n",
    "        print('\\t'+str(model)[:20]+\"...\", end=' - ')\n",
    "        preds = cross_val_predict(model,X,y,cv=num_folds)\n",
    "        print('OK')\n",
    "        \n",
    "        return preds\n",
    "\n",
    "    def run_all_save(num_folds,filename):\n",
    "        '''\n",
    "        @author José F. Díez Pastor\n",
    "        Perform cross validation with all models and datasets.\n",
    "            \n",
    "            \n",
    "        Parameters\n",
    "        ----------\n",
    "        num_folds: int\n",
    "            number of folds in the cross validation\n",
    "        filename: string\n",
    "            name of the file that stores the predictions obtained using crossvalidation\n",
    "            \n",
    "        Return\n",
    "        -------\n",
    "        \n",
    "        ''' \n",
    "        \n",
    "        all_preds = {}\n",
    "\n",
    "        for dataset,dataset_name in tqdm(zip(datasets, datasets_names)):\n",
    "            print(f\"----------Pre-trained network: {dataset_name}-----------\")\n",
    "            X,y = dataset\n",
    "            for model,cls_name in zip(classifiers,cls_names):\n",
    "                print(f\"-> {cls_name}\")\n",
    "                preds = cross_validate_preds_model(X, y, model, num_folds)\n",
    "                all_preds[(dataset_name,cls_name)]=(y,preds)\n",
    "\n",
    "        all_preds[\"cls_names\"]=cls_names\n",
    "        all_preds[\"dataset_names\"]=datasets_names\n",
    "\n",
    "        with open(filename, 'wb') as fp:\n",
    "            pickle.dump(all_preds, fp)\n",
    "    \n",
    "        ''' \n",
    "    Extract features: extracción de features pasandole una imágen y el modelo a utilizar\n",
    "    '''\n",
    "    def extract_features(image_path, model_name):\n",
    "        '''\n",
    "        model_name extaerá los features de la imagen que se le pase como parámetro.\n",
    "        '''\n",
    "        model_dict = confi['3.1_extraction']['models_dict'][model_name]\n",
    "        ####\n",
    "        model = model_dict[\"model\"]\n",
    "        preprocessor = model_dict[\"preprocesor\"]\n",
    "        target_size = model_dict[\"target_size\"]\n",
    "        # se carga la imagen y después se ajusta al input shape del modelo\n",
    "        img = cv2.resize(cv2.imread(image_path),target_size)\n",
    "\n",
    "        img_data = image.img_to_array(img)\n",
    "        img_data = np.expand_dims(img_data, axis=0)\n",
    "        img_data = preprocessor(img_data)\n",
    "        \n",
    "        # extracción de features\n",
    "        features = model.predict(img_data)\n",
    "        return features[0]\n",
    "\n",
    "    \n",
    "    freq = 1500\n",
    "    dur = 1000\n",
    "\n",
    "    obj_file = \"evaluation_models.obj\"\n",
    "\n",
    "    run_all_save(4,obj_file) # 4 folds (divisor de 756)\n",
    "    winsound.Beep(freq,dur)\n",
    "\n",
    "    def get_results(filename):\n",
    "        '''\n",
    "        @author: José F. Diez Pastor\n",
    "        Load the file with the predictions.\n",
    "        Compute accuracy, confusion matrix and other measures.\n",
    "            \n",
    "            \n",
    "        Parameters\n",
    "        ----------\n",
    "        filename: string\n",
    "            name of the file that stores the predictions obtained using crossvalidation\n",
    "            \n",
    "        Return\n",
    "        dictionary\n",
    "            A dictionary of key:values that asociates the name\n",
    "            of a measure or chart with the value\n",
    "        -------\n",
    "        \n",
    "        ''' \n",
    "\n",
    "        with open(filename, 'rb') as fp:\n",
    "            all_preds = pickle.load(fp)\n",
    "\n",
    "        cls_names = all_preds.pop(\"cls_names\")\n",
    "        dataset_names = all_preds.pop(\"dataset_names\")\n",
    "\n",
    "        data_cls_pairs = list(all_preds.keys())\n",
    "        data_cls_pairs.sort()\n",
    "\n",
    "        results = {}\n",
    "\n",
    "\n",
    "        acc_df = pd.DataFrame(index=dataset_names, columns=cls_names)\n",
    "\n",
    "        ## A DataFrame is created to store the accuracy in each clase\n",
    "        for dataset in dataset_names:\n",
    "            results[(dataset,\"acc\")] = pd.DataFrame(columns=cls_names)\n",
    "\n",
    "\n",
    "        for dataset_name,cls_name in tqdm(data_cls_pairs):\n",
    "            #print(dataset_name,cls_name)\n",
    "            y_true, y_pred = all_preds[(dataset_name,cls_name)]\n",
    "            labels = list(np.unique(y_true))\n",
    "\n",
    "            acc = accuracy_score(y_true, y_pred)\n",
    "            # Fill accuracy dataframe\n",
    "            acc_df.at[dataset_name,cls_name]=acc\n",
    "            \n",
    "            report = classification_report(y_true, y_pred, output_dict=True)\n",
    "            report_df = pd.DataFrame(report).transpose()\n",
    "            results[(dataset_name,cls_name,\"report\")] = report_df\n",
    "\n",
    "        results[\"Acc\"] = acc_df\n",
    "        return results\n",
    "\n",
    "\n",
    "    results = get_results(obj_file)\n",
    "\n",
    "    precisions = {}\n",
    "    for i in results.keys():\n",
    "        if i[-1] == \"report\":\n",
    "            print(i,end=\" -> \")\n",
    "            print(results[i][\"precision\"][-3])\n",
    "            precisions[results[i][\"precision\"][-3]] = i\n",
    "    highest_precision = precisions[max(precisions)]\n",
    "    highest_precision\n",
    "\n",
    "    best_model = highest_precision[0]\n",
    "    best_classifier = highest_precision[1]\n",
    "    print(f\"Best Precision: \\n\\t - Model: {best_model}\\n\\t - Classifier: {best_classifier}\")\n",
    "\n",
    "    X, y = datasets[1] #datasets = [(vgg_X,y), (inception_X,y), (resnet_X,y)]\n",
    "\n",
    "    # Dividimos los datos en entranamiento (80%) y testeo dejando (20%)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "    clf = classifiers[2] # LogisticRegression\n",
    "\n",
    "    clf.fit(X_train,y_train)\n",
    "\n",
    "    clf.score(X_test, y_test)\n",
    "\n",
    "    # guardamos el modelo\n",
    "    dump(clf, \"logistic_clf_trained.pkl\")\n",
    "\n",
    "    print(confi['3.1_extraction'])\n",
    "\n",
    "    ''' \n",
    "    Última etapa del reconocimiento: Matching\n",
    "    '''\n",
    "    ### Reconocer un sujeto (CASIA_IrisV1_unif_segv2_edg_norm)\n",
    "    img = confi['general']['dataset_unif_segv2_edg_norm_dir'] + '/001_1_1.bmp' # cambiar ruta a directorio CASIA_IrisV1_unif_segv2_edg_norm\n",
    "    test_sample = extract_features(img, \"InceptionV3\")\n",
    "\n",
    "    # cambiamos el shape para que los transforme a una fila\n",
    "    test_sample.shape = [1,2048]\n",
    "\n",
    "    prediction = clf.predict(test_sample)\n",
    "\n",
    "    prediction_prob = clf.predict_proba(test_sample)\n",
    "\n",
    "    labels = np.unique(y) # 108 individuos\n",
    "\n",
    "    #juntamos individuos y la probabilidades\n",
    "    predicted_dict = dict(zip(prediction_prob[0], labels))\n",
    "\n",
    "    print(predicted_dict)\n",
    "\n",
    "\n",
    "    # 5 individuos más probables \n",
    "    top_five = heapq.nlargest(5, predicted_dict)\n",
    "    labels, probs = [], []\n",
    "    for k,v in predicted_dict.items():\n",
    "        if k in top_five:\n",
    "            print(v+\" -> \"+str(k)+\"%\")\n",
    "            labels.append(v)\n",
    "            probs.append(k)\n",
    "\n",
    "    y_pos = np.arange(len(labels))\n",
    "    fig = plt.figure(figsize = (10,5))\n",
    "    plt.bar(labels, [i*100 for i in probs], color = 'green', width = 0.6)\n",
    "\n",
    "    plt.xticks(y_pos, labels)\n",
    "    plt.ylabel('Prediction %')\n",
    "    plt.title('Iris Prediction...')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    modelo_cargado = load(\"logistic_clf_trained.pkl\")\n",
    "    test_sample = extract_features(confi['general']['dataset_unif_segv2_edg_norm_dir'] + '\\002_1_1.bmp', \"InceptionV3\")\n",
    "    test_sample.shape = [1,test_sample.shape[0]]\n",
    "    modelo_cargado.predict(test_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 CNN model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## clasificationCNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clasificationCNN(confi):\n",
    "    print(\"Función 4, clasificationCNN()\")\n",
    "\n",
    "    ''' \n",
    "    Importando librerías\n",
    "    '''\n",
    "    try:\n",
    "        from keras.applications.vgg16 import VGG16\n",
    "        from tensorflow import keras\n",
    "        from tensorflow.keras import layers\n",
    "    except:\n",
    "        !pip install keras\n",
    "    try:\n",
    "        import tensorflow as tf\n",
    "    except:\n",
    "        !pip install tensorflow\n",
    "        import tensorflow as tf\n",
    "    try:\n",
    "        import numpy as np\n",
    "    except:\n",
    "        !pip install numpy\n",
    "        import numpy as np\n",
    "    try:\n",
    "        import pathlib\n",
    "    except:\n",
    "        import pathlib\n",
    "        !pip install pathlib\n",
    "    try:\n",
    "        import matplotlib.pyplot as plt\n",
    "    except:\n",
    "        !pip install matplotlib\n",
    "        import matplotlib.pyplot as plt\n",
    "    try:\n",
    "        import os\n",
    "    except:\n",
    "        !pip install os\n",
    "    try:\n",
    "        import random\n",
    "    except:\n",
    "        !pip install random\n",
    "        import random\n",
    "        \n",
    "    model = VGG16(weights=confi['4_CNN_classification']['CNN_weights'])\n",
    "\n",
    "    if confi['4_CNN_classification']['dataset_dir'] == 'normalizado':\n",
    "\n",
    "        IMAGE_PATHS_DIR = confi['general']['dataset_unif_segv2_edg_norm_dir']\n",
    "    \n",
    "    elif confi['4_CNN_classification']['dataset_dir'] == 'raw':\n",
    "\n",
    "        IMAGE_PATHS_DIR = confi['general']['dataset_unif_dir']\n",
    "\n",
    "    paths = np.array([x.__str__() for x in pathlib.Path(IMAGE_PATHS_DIR).rglob('*.bmp')])\n",
    "    \n",
    "    random.shuffle(paths)\n",
    "    \n",
    "    filenames = tf.constant(paths)\n",
    "    \n",
    "    print(f\"paths {paths}\")\n",
    "    \n",
    "    labels_array = np.array([x.split(\"/\")[-1].split(\"_\")[0] for x in paths])\n",
    "    labels = tf.constant(labels_array)\n",
    "    \n",
    "    print(f\"labels_array {labels_array}\")\n",
    "\n",
    "    n_clases = np.max([int(i) for i in labels_array])\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((filenames, labels))\n",
    "\n",
    "    dataset_len = len(dataset)\n",
    "\n",
    "    print(f\"Dataset len: {dataset_len}\")\n",
    "\n",
    "    train_size = int(confi['4_CNN_classification']['train_size'] * dataset_len)\n",
    "    test_size = int(confi['4_CNN_classification']['test_size'] * dataset_len)\n",
    "\n",
    "    print(f\"train size: {train_size}\")\n",
    "    print(f\"test size: {test_size}\")\n",
    "\n",
    "    def _parse_function(filename, label):\n",
    "        img = tf.io.read_file(filename)\n",
    "        image = tf.image.decode_bmp(img, channels = 3)\n",
    "        label = int(label)\n",
    "        return image, label\n",
    "\n",
    "    dataset = dataset.map(_parse_function)\n",
    "\n",
    "    train_ds = dataset.take(train_size)\n",
    "    test_ds = dataset.skip(train_size)\n",
    "\n",
    "    size = (224, 224)\n",
    "\n",
    "    train_ds = train_ds.map(lambda x, y: (tf.image.resize(x, size), y))\n",
    "    test_ds = test_ds.map(lambda x, y: (tf.image.resize(x, size), y))\n",
    "\n",
    "    def label_preprocess(image, label):\n",
    "        label = tf.one_hot(label-1, n_clases) \n",
    "        return image, label\n",
    "\n",
    "    train_ds = train_ds.map(label_preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    batch_size = confi['4_CNN_classification']['batch_size']\n",
    "    train_ds = train_ds.batch(batch_size=batch_size, drop_remainder=True)\n",
    "    train_ds = train_ds.prefetch(tf.data.AUTOTUNE)\n",
    "    test_ds = test_ds.map(label_preprocess)\n",
    "    test_ds = test_ds.batch(batch_size=batch_size, drop_remainder=True)\n",
    "\n",
    "    if batch_size > dataset_len:\n",
    "        print(f\"El modelo fallará puesto que el número de elemento en el dataset {dataset_len} es menor que el tamño del batch {batch_size}\")\n",
    "\n",
    "    ''' \n",
    "    Create base model\n",
    "    '''\n",
    "    base_model = keras.applications.Xception(\n",
    "        weights=confi['4_CNN_classification']['CNN_weights'],  # Load weights pre-trained on ImageNet.\n",
    "        input_shape=(224, 224, 3),\n",
    "        include_top=False,\n",
    "    )  # Do not include the ImageNet classifier at the top.\n",
    "\n",
    "    # Freeze the base_model\n",
    "    base_model.trainable = False\n",
    "\n",
    "    # Create new model on top\n",
    "    inputs = keras.Input(shape=(224, 224, 3))\n",
    "\n",
    "    outputs = VGG16(include_top=True, weights=None, classes=n_clases)(inputs)\n",
    "    model = keras.Model(inputs, outputs)\n",
    "\n",
    "    model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "    epochs = confi['4_CNN_classification']['epochs1']  # @param {type: \"slider\", min:10, max:100}\n",
    "    hist = model.fit(train_ds, epochs=epochs, validation_data=test_ds, verbose=2)\n",
    "\n",
    "    def plot_hist(hist):\n",
    "        plt.plot(hist.history[\"accuracy\"])\n",
    "        plt.plot(hist.history[\"val_accuracy\"])\n",
    "        plt.title(\"model accuracy\")\n",
    "        plt.ylabel(\"accuracy\")\n",
    "        plt.xlabel(\"epoch\")\n",
    "        plt.legend([\"train\", \"validation\"], loc=\"upper left\")\n",
    "        plt.show()\n",
    "\n",
    "    if confi['4_CNN_classification']['plt_accuracy1']:\n",
    "        plot_hist(hist)\n",
    "\n",
    "    def build_model(num_classes):\n",
    "        inputs = layers.Input(shape=(224, 224, 3))\n",
    "        model = VGG16(include_top=False, input_tensor=inputs, weights=confi['4_CNN_classification']['CNN_weights'])\n",
    "\n",
    "        # Freeze the pretrained weights\n",
    "        model.trainable = False\n",
    "        # Rebuild top\n",
    "        x = layers.GlobalAveragePooling2D(name=\"avg_pool\")(model.output)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "\n",
    "        top_dropout_rate = 0.2\n",
    "        x = layers.Dropout(top_dropout_rate, name=\"top_dropout\")(x)\n",
    "        outputs = layers.Dense(num_classes, activation=\"softmax\", name=\"pred\")(x)\n",
    "\n",
    "        # Compile\n",
    "        model = keras.Model(inputs, outputs)\n",
    "        optimizer = keras.optimizers.Adam(learning_rate=1e-2)\n",
    "        model.compile(\n",
    "            optimizer=optimizer, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    "        )\n",
    "        return model\n",
    "\n",
    "    model = build_model(num_classes=n_clases)\n",
    "    epochs = confi['4_CNN_classification']['epochs2']  # @param {type: \"slider\", min:8, max:80}\n",
    "    hist = model.fit(train_ds, epochs=epochs, validation_data=test_ds, verbose=2)\n",
    "\n",
    "    if confi['4_CNN_classification']['plt_accuracy2']:\n",
    "        plot_hist(hist)\n",
    "\n",
    "    def unfreeze_model(model):\n",
    "        # We unfreeze the top 20 layers while leaving BatchNorm layers frozen\n",
    "        for layer in model.layers[-20:]:\n",
    "            if not isinstance(layer, layers.BatchNormalization):\n",
    "                layer.trainable = True\n",
    "\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
    "        model.compile(\n",
    "            optimizer=optimizer, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    "        )\n",
    "\n",
    "    unfreeze_model(model)\n",
    "\n",
    "    epochs = confi['4_CNN_classification']['epochs3']  # @param {type: \"slider\", min:8, max:50}\n",
    "    hist = model.fit(train_ds, epochs=epochs, validation_data=test_ds, verbose=2)\n",
    "\n",
    "    if confi['4_CNN_classification']['plt_accuracy3']:\n",
    "        plot_hist(hist)\n",
    "\n",
    "    size = (224, 224)\n",
    "\n",
    "    def _parse_image(filename):\n",
    "        img = tf.io.read_file(filename)\n",
    "        img = tf.image.decode_bmp(img, channels = 3)\n",
    "        img = tf.image.resize(img, size)\n",
    "        img = tf.expand_dims(img, 0)\n",
    "        return img\n",
    "\n",
    "    try_dataset_path = os.listdir(IMAGE_PATHS_DIR)\n",
    "    try_dataset_len = len(try_dataset_path)\n",
    "    try_image_name = try_dataset_path[random.randint(0, try_dataset_len)]\n",
    "    try_image_path = IMAGE_PATHS_DIR + os.sep + try_image_name\n",
    "    try_image_class = int(try_image_path.split(\"/\")[-1].split(\"_\")[0])\n",
    "    try_image = _parse_image(try_image_path)\n",
    "    result = model.predict(try_image)\n",
    "\n",
    "    print(f\"Actiual class is {try_image_class} and the predicted class is: {np.argmax(result) + 1}\")\n",
    "\n",
    "    if confi['4_CNN_classification']['results_array']:\n",
    "        print(result)\n",
    "        label_int = np.unique([int(i) for i in labels_array])\n",
    "        probs = result[0]\n",
    "        y_pos = np.arange(n_clases)\n",
    "        fig = plt.figure(figsize = (10,5))   \n",
    "        plt.bar([x - 1 for x in label_int], [i*100 for i in probs], width = 0.2)\n",
    "        plt.xticks(y_pos, label_int)\n",
    "        plt.ylabel('Prediction %')\n",
    "        plt.title('Iris Prediction...')\n",
    "        plt.show()\n",
    "\n",
    "    if confi['4_CNN_classification']['save_model']:\n",
    "        model.save(confi['4_CNN_classification']['save_model_name'])\n",
    "        print(\"Model saved\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definir y ejecutar el pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definición del pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from sklearn.preprocessing import FunctionTransformer\n",
    "    from sklearn.pipeline import Pipeline\n",
    "except:\n",
    "    !pip install scikit-learn\n",
    "    from sklearn.preprocessing import FunctionTransformer\n",
    "    from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_1_tratar_dataset_pip = FunctionTransformer(tratar_dataset_casia)\n",
    "_1_1_data_augmentation_pip = FunctionTransformer(data_augmentation)\n",
    "_2_1_segmentation_pip = FunctionTransformer(segmentation)\n",
    "_2_2_normalization_pip = FunctionTransformer(normalization)\n",
    "#_3_1_extraction_pip = FunctionTransformer(extraction)\n",
    "#_3_2_clasification_pip = FunctionTransformer(clasification)\n",
    "_4_clasificationCNN_pip = FunctionTransformer(clasificationCNN)\n",
    "\n",
    "# iris_recognition_pipeline = Pipeline([('_1_tratarDataset', _1_tratar_dataset_pip), \n",
    "#                                     ('_1_1_dataAugmentation', _1_1_data_augmentation_pip), \n",
    "#                                     ('_2_1_segmentation', _2_1_segmentation_pip), \n",
    "#                                     ('_2_2_normalization', _2_2_normalization_pip),\n",
    "#                                     ('_3_1_extraction', _3_1_extraction_pip),\n",
    "#                                     ('_3_2_clasification', _3_2_clasification_pip), \n",
    "#                                     ('_4_clasificationCNN', _4_clasificationCNN_pip)\n",
    "#                                                                                   ])\n",
    "\n",
    "iris_recognition_pipeline = Pipeline([('_1_tratarDataset', _1_tratar_dataset_pip),  \n",
    "                                    ('_2_1_segmentation', _2_1_segmentation_pip), \n",
    "                                    ('_2_2_normalization', _2_2_normalization_pip), \n",
    "                                    ('_4_clasificationCNN', _4_clasificationCNN_pip)])\n",
    "\n",
    "# iris_recognition_pipeline = Pipeline([('_1_tratarDataset', _1_tratar_dataset_pip), \n",
    "#                                     ('_4_clasificationCNN', _4_clasificationCNN_pip)])\n",
    "\n",
    "# iris_recognition_pipeline = Pipeline([('_1_tratarDataset', _1_tratar_dataset_pip)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejecición pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_recognition_pipeline.transform(confi_dict)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0600588c3b5f4418cbe7b5ebc6825b479f3bc010269d8b60d75058cdd010adfe"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
