{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Pipeline configuration"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "confi_dict = {\r\n",
    "\r\n",
    "    'general':{\r\n",
    "        'root_dir':r\"C:\\Users\\na-ch\\Desktop\\estudio\\Master_Big_Data\\03_TFM\\02_Code\\dataset_test\",\r\n",
    "        'dataset_dir': \"CASIA_IrisV1\"\r\n",
    "    },\r\n",
    "\r\n",
    "    '1_tratarDataset':{\r\n",
    "        'show_first' : False\r\n",
    "    },\r\n",
    "\r\n",
    "    '1.1_dataAugmentation':{\r\n",
    "        'gaussianNoise' : False,\r\n",
    "        'stdGN': [5, 10, 15, 20],\r\n",
    "        'skipFiles': 1, \r\n",
    "        ''' \r\n",
    "        1 means that you are skiping 1 for the noise augmentation, \r\n",
    "        2 skiping 2 and so on. If you don't want to skip files set it as 0\r\n",
    "        '''\r\n",
    "        'afinTransformation': False\r\n",
    "    },\r\n",
    "\r\n",
    "    '2.1_segmentation':{\r\n",
    "        'redNeuronal' : \"Iris_unet_d5.h5\", \r\n",
    "        'numSamplesGenerator' : 3, \r\n",
    "        'verImagenV1' : False\r\n",
    "    },\r\n",
    "\r\n",
    "    '3.1_extraction': {\r\n",
    "        \r\n",
    "    }\r\n",
    "\r\n",
    "}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1: Tratar el dataset CASIA\r\n",
    "\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1 tratar_dataset_casia()"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "def tratar_dataset_casia(confi):\r\n",
    "    \r\n",
    "    print(\"Función 1, tratar_dataset_casia()\")\r\n",
    "    \r\n",
    "    ''' \r\n",
    "    Importando librerías\r\n",
    "    '''\r\n",
    "    try:\r\n",
    "        import os\r\n",
    "    except:\r\n",
    "        !pip install os\r\n",
    "        import os\r\n",
    "    try:\r\n",
    "        import shutil\r\n",
    "    except:\r\n",
    "        !pip install shutil\r\n",
    "        import shutil\r\n",
    "    try:\r\n",
    "         import imageio\r\n",
    "    except:\r\n",
    "        !pip install imageio\r\n",
    "        import imageio\r\n",
    "    try:\r\n",
    "        import matplotlib.pyplot as plt\r\n",
    "    except:\r\n",
    "        !pip install matplotlib\r\n",
    "        import matplotlib.pyplot as plt\r\n",
    "    ''' \r\n",
    "    Estableciendo la root de la función\r\n",
    "    '''\r\n",
    "    os.chdir(confi['general']['root_dir'])\r\n",
    "    \r\n",
    "    def copy_all_samples(path_samples, destination_directory):\r\n",
    "        '''\r\n",
    "        Copia todas las muestras del dataset de CASIA a un único directorio.\r\n",
    "        '''\r\n",
    "        if not os.path.exists(path_samples):\r\n",
    "            print(\"->El directorio indicado como input no existe\")\r\n",
    "        elif not os.path.exists(destination_directory):\r\n",
    "            ''' \r\n",
    "            Comprobamos que el directorio del output no existe\r\n",
    "            '''\r\n",
    "            os.mkdir(destination_directory) # Creamos un nuevo directorio \r\n",
    "            for root, dirs, files in os.walk(path_samples):\r\n",
    "                for file in files:\r\n",
    "                    path_file = os.path.join(root,file)\r\n",
    "                    shutil.copy2(path_file,destination_directory)   \r\n",
    "            print(\"-> Muestras copiadas satisfactoriamente.\")\r\n",
    "        elif len(os.listdir(destination_directory)) < 1:\r\n",
    "            ''' \r\n",
    "            Comprobamos que el directorio del output no está vacío\r\n",
    "            '''\r\n",
    "            for root, dirs, files in os.walk(path_samples):\r\n",
    "                for file in files:\r\n",
    "                    path_file = os.path.join(root,file)\r\n",
    "                    shutil.copy2(path_file,destination_directory)   \r\n",
    "            print(\"-> Muestras copiadas satisfactoriamente.\")\r\n",
    "        else:\r\n",
    "            print(\"-> Muestras previamente copiadas.\")\r\n",
    "\r\n",
    "    confi['general']['dataset_unif_dir'] = confi['general']['dataset_dir']+\"_unif\"\r\n",
    "\r\n",
    "    copy_all_samples(confi['general']['dataset_dir'], confi['general']['dataset_unif_dir'])\r\n",
    "\r\n",
    "    if confi['1_tratarDataset']['show_first']:\r\n",
    "        ''' \r\n",
    "        Si en la configuración show_first es True, se mostrará el primer elemento del nuevo directorio.\r\n",
    "        '''\r\n",
    "        path_img = confi['general']['dataset_unif_dir'] + os.sep + os.listdir(confi['general']['dataset_unif_dir'])[0]\r\n",
    "        img = imageio.imread(path_img)\r\n",
    "        plt.title(\"Primer elemento de \" + confi['general']['dataset_unif_dir'])\r\n",
    "        plt.imshow(img)\r\n",
    "    \r\n",
    "    ''' \r\n",
    "    Pasando el diccionario con la configuración a la siguiente función\r\n",
    "    '''\r\n",
    "    return confi\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.1 data_augmentation()"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "def data_augmentation(confi):\r\n",
    "\r\n",
    "    print(\"Función 1.1, data_augmentation()\")\r\n",
    "    \r\n",
    "    ''' \r\n",
    "    Importando librerías\r\n",
    "    '''\r\n",
    "    try:\r\n",
    "        import os\r\n",
    "    except:\r\n",
    "        !pip install os\r\n",
    "        import os\r\n",
    "    try:\r\n",
    "        import imageio\r\n",
    "    except:\r\n",
    "        !pip install imageio\r\n",
    "        import imageio\r\n",
    "    try:\r\n",
    "        import skimage.io as io\r\n",
    "    except:\r\n",
    "        !pip install scikit-image\r\n",
    "        import skimage.io as io\r\n",
    "    try:\r\n",
    "        import matplotlib.pyplot as plt\r\n",
    "    except:\r\n",
    "        !pip install matplotlib\r\n",
    "        import matplotlib.pyplot as plt\r\n",
    "    try:\r\n",
    "        from tensorflow.keras.layers import GaussianNoise\r\n",
    "    except:\r\n",
    "        !pip install tensorflow\r\n",
    "        from tensorflow.keras.layers import GaussianNoise\r\n",
    "    try:\r\n",
    "        import numpy as np\r\n",
    "    except:\r\n",
    "        !pip install numpy\r\n",
    "        import numpy as np\r\n",
    "    import random\r\n",
    "\r\n",
    "    ''' \r\n",
    "    Estableciendo la root de la función\r\n",
    "    '''\r\n",
    "    os.chdir(confi['general']['root_dir'])\r\n",
    "    \r\n",
    "    ''' \r\n",
    "    Comprobamos si el ruido gaussiano ha sido establecido como True en la configuración\r\n",
    "    '''\r\n",
    "\r\n",
    "    if confi['1.1_dataAugmentation']['gaussianNoise']:\r\n",
    "\r\n",
    "        ''' \r\n",
    "        Comprobamos si el ruido gaussiano se ha aplicado anteriormente, si es así, el primer elemento del directorio debería de tener el sufijo _augmentation\r\n",
    "        '''\r\n",
    "        if \"_augment\" in os.listdir(confi['general']['dataset_unif_dir'])[1]:\r\n",
    "            print(\"->El ruido gaussiano ya se ha ejecutado con anterioridad\")\r\n",
    "        else:     \r\n",
    "            ''' \r\n",
    "            Desde el directorio unificado creamos nuevas imágenes utilizando el ruido gaussiano como data augmentation.\r\n",
    "            Añadimos un contador para que el augmentation sea de 1 cada dos imágenes.\r\n",
    "            '''\r\n",
    "            i = 0\r\n",
    "            for filename in os.listdir(confi['general']['dataset_unif_dir']):\r\n",
    "                if confi['1.1_dataAugmentation']['skipFiles'] == 0:\r\n",
    "                    path = confi['general']['dataset_unif_dir'] + os.sep + filename\r\n",
    "                    image = imageio.imread(path)/255\r\n",
    "                    std_rdm = random.choice(confi['1.1_dataAugmentation']['stdGN'])\r\n",
    "                    gaussean_function = GaussianNoise(std_rdm/100)\r\n",
    "                    noisey = gaussean_function(image.astype(np.float32),training=True)\r\n",
    "                    name = path[:-4] + '_augment.bmp'\r\n",
    "                    plt.imsave(name, noisey, cmap='gray')\r\n",
    "                elif i < confi['1.1_dataAugmentation']['skipFiles']:\r\n",
    "                    path = confi['general']['dataset_unif_dir'] + os.sep + filename\r\n",
    "                    image = imageio.imread(path)/255\r\n",
    "                    std_rdm = random.choice(confi['1.1_dataAugmentation']['stdGN'])\r\n",
    "                    gaussean_function = GaussianNoise(std_rdm/100)\r\n",
    "                    noisey = gaussean_function(image.astype(np.float32),training=True)\r\n",
    "                    name = path[:-4] + '_augment.bmp'\r\n",
    "                    io.imsave(name, noisey)\r\n",
    "                    i += 1\r\n",
    "                else:\r\n",
    "                    i = 0\r\n",
    "            print(\"->Data augmentation 'ruido gausseano' ejecutado correctamente\")\r\n",
    "    else:\r\n",
    "        print(\"->Saltando el ruido gausseano en data augmentation\")\r\n",
    "\r\n",
    "    ''' \r\n",
    "    Pasando el diccionario con la configuración a la siguiente función\r\n",
    "    '''\r\n",
    "    return confi"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2 Red U-Net v2"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.1 segmentation()"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "def segmentation(confi):\r\n",
    "\r\n",
    "    print(\"Función 2.1, segmentation()\")\r\n",
    "\r\n",
    "    ''' \r\n",
    "    Importando librerías\r\n",
    "    '''\r\n",
    "    try:\r\n",
    "        import os\r\n",
    "    except:\r\n",
    "        !pip install os\r\n",
    "        import os\r\n",
    "    try:\r\n",
    "        import cv2\r\n",
    "    except:\r\n",
    "        import cv2\r\n",
    "    try:\r\n",
    "        import shutil\r\n",
    "    except:\r\n",
    "        !pip install shutil\r\n",
    "        import shutil\r\n",
    "    try:\r\n",
    "         import imageio\r\n",
    "    except:\r\n",
    "        !pip install imageio\r\n",
    "        import imageio\r\n",
    "    try:\r\n",
    "        import skimage.transform as trans\r\n",
    "        from skimage.io import imshow\r\n",
    "        import skimage.io as io\r\n",
    "    except:\r\n",
    "        !pip install scikit-image\r\n",
    "        import skimage.transform as trans\r\n",
    "        from skimage.io import imshow\r\n",
    "        import skimage.io as io\r\n",
    "    try:\r\n",
    "        import matplotlib.pyplot as plt\r\n",
    "    except:\r\n",
    "        !pip install matplotlib\r\n",
    "        import matplotlib.pyplot as plt\r\n",
    "    try:\r\n",
    "        from keras.models import load_model\r\n",
    "    except:\r\n",
    "        !pip install tensorflow \r\n",
    "        from keras.models import load_model\r\n",
    "    try:\r\n",
    "        import numpy as np\r\n",
    "    except:\r\n",
    "        !pip install numpy\r\n",
    "        import numpy as np\r\n",
    "    try:\r\n",
    "        from PIL import Image\r\n",
    "    except:\r\n",
    "        !pip install Pillow\r\n",
    "        from PIL import Image\r\n",
    "    ''' \r\n",
    "    Estableciendo la root de la función\r\n",
    "    '''\r\n",
    "    os.chdir(confi['general']['root_dir'])\r\n",
    "\r\n",
    "    ''' \r\n",
    "    Creamos un generador con un número n de imágenes para pasarselas al modelo en el predict\r\n",
    "    *Recordemos que este modelo ya está entrenado para la segmentación del ojo\r\n",
    "    '''\r\n",
    "    def testGenerator(directory, target_size = (320,320)):\r\n",
    "        '''\r\n",
    "        Genera las muestras que se le pasarán al método predecir de la red preentrenada.\r\n",
    "        \r\n",
    "        Parámetros:\r\n",
    "        directory -- directorio dónde se encuentran las muestras a generar\r\n",
    "        num_image -- número máximo de imágenes que queremos generar\r\n",
    "        target_size -- shape de de la muestra\r\n",
    "        flag_multi_class -- (de momento mantener pero no nos es útil)\r\n",
    "        '''\r\n",
    "        for file in os.listdir(directory):\r\n",
    "            path_file = os.path.join(directory,file)\r\n",
    "            img = imageio.imread(path_file)\r\n",
    "            img = img / 255\r\n",
    "            img = trans.resize(img,target_size)\r\n",
    "            img = np.reshape(img, img.shape+(1,))\r\n",
    "            img = np.reshape(img, (1,) + img.shape)\r\n",
    "            yield img\r\n",
    "    \r\n",
    "    def get_samples_names(directory):\r\n",
    "        '''\r\n",
    "        Devuelve los nombres de las muestras (los que se encuentran en los directorios hoja)\r\n",
    "        \r\n",
    "        Parámetros:\r\n",
    "        directory -- directorio de cuyos subdirectorios hoja se quiere el nombre \r\n",
    "        '''\r\n",
    "        names = []\r\n",
    "        for file in os.listdir(directory):\r\n",
    "            names.append(str(file))\r\n",
    "                \r\n",
    "        return names\r\n",
    "\r\n",
    "    def saveResult(save_path, name_path, npyfile):\r\n",
    "        '''\r\n",
    "        Guarda los imágenes segmentadas resultado de la red preentrenada\r\n",
    "        \r\n",
    "        Parámetros:\r\n",
    "        save_path -- ruta en la que se guardarán las muestras segmentadas\r\n",
    "        name_path -- directorio del que cogeremos los nombres de las muestras\r\n",
    "        npyfile -- resultado de la red preentrenada\r\n",
    "        '''\r\n",
    "        dim = (320, 280) # dimensioned de las muestras del dataset\r\n",
    "        os.mkdir(save_path)\r\n",
    "        names = get_samples_names(name_path)\r\n",
    "        for i, item in enumerate(npyfile):\r\n",
    "            img = item[:,:,0]\r\n",
    "            img = cv2.resize(img, dim, interpolation=cv2.INTER_AREA)\r\n",
    "            io.imsave(os.path.join(save_path,names[i]),img)    \r\n",
    "\r\n",
    "    confi['general']['dataset_unif_seg_dir'] =  confi['general']['dataset_unif_dir']  + \"_seg\"\r\n",
    "    if not os.path.exists(confi['general']['dataset_unif_seg_dir']):\r\n",
    "        ''' \r\n",
    "        Cargamos el modelo de segmentación\r\n",
    "        '''\r\n",
    "        model = load_model(confi['2.1_segmentation']['redNeuronal'])\r\n",
    "        print(\"->Modelo cargado\")\r\n",
    "        testGene = testGenerator(confi['general']['dataset_unif_dir'])\r\n",
    "        Unet_results = model.predict(testGene, verbose=1) \r\n",
    "        saveResult(confi['general']['dataset_unif_seg_dir'], confi['general']['dataset_unif_dir'], Unet_results)\r\n",
    "        print(\"->Segmentaciones guardadas\")\r\n",
    "    else:\r\n",
    "        print(\"->Segmentaciones previamente guardadas\")\r\n",
    "\r\n",
    "    if confi['2.1_segmentation']['verImagenV1']:\r\n",
    "        sample = \"001_1_1.bmp\"\r\n",
    "        path_img = confi['general']['dataset_unif_dir'] + os.sep + sample\r\n",
    "        path_back = confi['general']['dataset_unif_seg_dir'] + os.sep + sample\r\n",
    "        image = Image.open(path_img)\r\n",
    "        background = Image.open(path_back)\r\n",
    "        background.paste(image, (0, 0), image)\r\n",
    "        plt.imshow(background, cmap='gray');\r\n",
    "    \r\n",
    "    confi['general']['dataset_unif_segv2_dir'] = confi['general']['dataset_unif_seg_dir'] + \"v2\"\r\n",
    "    confi['general']['dataset_unif_segv2_edg_dir'] = confi['general']['dataset_unif_segv2_dir'] + \"_edg\"\r\n",
    "\r\n",
    "    segv2_dir = False\r\n",
    "    edge_dir = False\r\n",
    "\r\n",
    "    for file in os.listdir(confi['general']['dataset_unif_seg_dir']):\r\n",
    "        path_file = os.path.join(confi['general']['dataset_unif_seg_dir'],file)\r\n",
    "        img = cv2.imread(path_file)\r\n",
    "        blur= cv2.GaussianBlur(img,(17,17),0)\r\n",
    "        (thresh, binarized) = cv2.threshold(blur, 70, 255, cv2.THRESH_BINARY) # se binariza nuevamente\r\n",
    "        edges = cv2.Canny(binarized, 10, 255)\r\n",
    "\r\n",
    "        # creamos un nuevo directorio para guardar las muestras segmentadas con mayor calidad\r\n",
    "        if not os.path.exists(confi['general']['dataset_unif_segv2_dir']):\r\n",
    "            os.mkdir(confi['general']['dataset_unif_segv2_dir'])\r\n",
    "            cv2.imwrite(confi['general']['dataset_unif_segv2_dir'] + os.sep + file, binarized)\r\n",
    "            segv2_dir = True\r\n",
    "        elif segv2_dir:\r\n",
    "            cv2.imwrite(confi['general']['dataset_unif_segv2_dir'] + os.sep + file, binarized)\r\n",
    "        else:\r\n",
    "            print(\"->La segmentación v2 ya había sido creada\")\r\n",
    "            break \r\n",
    "\r\n",
    "        # creamos un nuevo directorio para guardar las muestras con los bordes detectados\r\n",
    "        if not os.path.exists(confi['general']['dataset_unif_segv2_edg_dir']):\r\n",
    "            os.mkdir(confi['general']['dataset_unif_segv2_edg_dir'])\r\n",
    "            cv2.imwrite(confi['general']['dataset_unif_segv2_edg_dir'] + os.sep + file, edges)# guardamos muestra\r\n",
    "            edge_dir = True\r\n",
    "        elif edge_dir:\r\n",
    "            cv2.imwrite(confi['general']['dataset_unif_segv2_edg_dir'] + os.sep + file, edges)# guardamos muestra\r\n",
    "        else:\r\n",
    "            print(\"->La edge ya había sido creada\")\r\n",
    "            break \r\n",
    "    \r\n",
    "    print(\"->Segmentaciones V2 guardadas\")\r\n",
    "    print(\"->Edge guardadas\")\r\n",
    "\r\n",
    "    return confi"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.2 normalization()"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "def normalization(confi):\r\n",
    "\r\n",
    "    print(\"Función 2.2, normalization()\")\r\n",
    "\r\n",
    "    ''' \r\n",
    "    Importando librerías\r\n",
    "    '''\r\n",
    "    try:\r\n",
    "        import os\r\n",
    "    except:\r\n",
    "        !pip install os\r\n",
    "        import os\r\n",
    "    try:\r\n",
    "        import cv2\r\n",
    "    except:\r\n",
    "        import cv2\r\n",
    "    try:\r\n",
    "        from skimage.transform import (hough_circle, hough_circle_peaks)\r\n",
    "        from skimage.io import imshow\r\n",
    "    except:\r\n",
    "        !pip install scikit-image\r\n",
    "        from skimage.transform import (hough_circle, hough_circle_peaks)\r\n",
    "        from skimage.io import imshow\r\n",
    "    try:\r\n",
    "         import imageio\r\n",
    "    except:\r\n",
    "        !pip install imageio\r\n",
    "        import imageio\r\n",
    "    try:\r\n",
    "        import numpy as np\r\n",
    "    except:\r\n",
    "        !pip install numpy\r\n",
    "        import numpy as np\r\n",
    "    try:\r\n",
    "        import matplotlib.pyplot as plt\r\n",
    "    except:\r\n",
    "        !pip install matplotlib\r\n",
    "        import matplotlib.pyplot as plt\r\n",
    "    try:\r\n",
    "        import pandas as pd\r\n",
    "    except:\r\n",
    "        !pip install pandas\r\n",
    "        import pandas as pd\r\n",
    "    ''' \r\n",
    "    Estableciendo la root de la función\r\n",
    "    '''\r\n",
    "    os.chdir(confi['general']['root_dir'])\r\n",
    "    ''' \r\n",
    "    Creando funciones\r\n",
    "    '''\r\n",
    "\r\n",
    "    def draw_circles(img, cx, cy, radii):\r\n",
    "        '''\r\n",
    "        A partir de los centros y el radio detectados dibuja el iris sobre la imagen que se le\r\n",
    "        pasa como parámetro.\r\n",
    "        '''\r\n",
    "        image = img.copy()\r\n",
    "        pupil = cv2.circle(image,(cx[0],cy[0]), radii[0]+3, (255, 0, 0), 2)\r\n",
    "        iris = cv2.circle(image,(cx[1],cy[1]), radii[1], (255, 0, 0), 2)\r\n",
    "        return image\r\n",
    "    \r\n",
    "    def get_circles(borde, sample):\r\n",
    "        path_sample = \"CASIA_IrisV1_unif\" + os.sep + sample\r\n",
    "        path_edged = \"CASIA_IrisV1_unif_segv2_edg\" + os.sep + sample\r\n",
    "        sample_ = imageio.imread(path_sample)\r\n",
    "        gray_img = imageio.imread(path_edged)\r\n",
    "        \r\n",
    "        hough_radii = np.arange(20, 80) # pupila por defecto\r\n",
    "        if borde == \"iris\":\r\n",
    "            hough_radii = np.arange(90, 160) # rango del iris\r\n",
    "        \r\n",
    "        hough_res = hough_circle(gray_img, hough_radii)\r\n",
    "        accums, cx, cy, radii = hough_circle_peaks(hough_res, hough_radii, total_num_peaks=1) \r\n",
    "\r\n",
    "        \r\n",
    "        return [cx[0], cy[0], radii[0]]\r\n",
    "\r\n",
    "    confi['general']['dataset_unif_segv2_edg_norm_dir'] = confi['general']['dataset_unif_segv2_edg_dir'] + \"_norm\"\r\n",
    "    \r\n",
    "    if not os.path.exists(confi['general']['dataset_unif_segv2_edg_norm_dir']):\r\n",
    "        os.mkdir(confi['general']['dataset_unif_segv2_edg_norm_dir'])\r\n",
    "    \r\n",
    "        image_files = []\r\n",
    "        new_dir = 'CASIA_IrisV1_unif_segv2_edg'\r\n",
    "\r\n",
    "        for root, dirs, files in os.walk(new_dir):\r\n",
    "            for file in files:\r\n",
    "                if file.endswith(\".bmp\"):\r\n",
    "                    image_files.append(file)\r\n",
    "                    \r\n",
    "        # cogemos las clases a las que pertenece cada .bmp\r\n",
    "        classes = []           \r\n",
    "        for name in image_files:\r\n",
    "            classes.append(name.split('_', 1)[0])\r\n",
    "        \r\n",
    "        x_pupil, y_pupil, r_pupil =[], [], []\r\n",
    "        x_iris, y_iris, r_iris =[],[],[]\r\n",
    "\r\n",
    "        for file in os.listdir(confi['general']['dataset_unif_segv2_dir']):\r\n",
    "\r\n",
    "            path_sample = \"CASIA_IrisV1_unif\" + os.sep + file\r\n",
    "            sample_image = imageio.imread(path_sample)\r\n",
    "            boundaries,centers, pupil_centers = [],[],[]\r\n",
    "            pupil_coord = get_circles(\"pupil\",file)\r\n",
    "            iris_coord = get_circles(\"iris\",file)\r\n",
    "            cx, cy, radius = list(zip(pupil_coord, iris_coord))\r\n",
    "            draw = draw_circles(sample_image,cx,cy,radius)\r\n",
    "\r\n",
    "            boundaries.append(draw)\r\n",
    "            data = {'pupil':pupil_coord,\r\n",
    "                    'iris':iris_coord}\r\n",
    "            centers.append(data)\r\n",
    "            pupil_centers.append(pupil_coord)\r\n",
    "\r\n",
    "            target = [img for img in boundaries]\r\n",
    "            normalized=[]\r\n",
    "            cent=0\r\n",
    "                \r\n",
    "            for img in target:\r\n",
    "                #load pupil centers and radius of inner circles\r\n",
    "                print(pupil_centers[0][0])\r\n",
    "                center_x = pupil_centers[cent][0]\r\n",
    "                center_y = pupil_centers[cent][1]\r\n",
    "                radius_pupil=int(pupil_centers[cent][2])\r\n",
    "\r\n",
    "                iris_radius = 53 # width of space between inner and outer boundary\r\n",
    "\r\n",
    "                #define equally spaced interval to iterate over\r\n",
    "                nsamples = 360\r\n",
    "                samples = np.linspace(0,2*np.pi, nsamples)[:-1]\r\n",
    "                polar = np.zeros((iris_radius, nsamples))\r\n",
    "                for r in range(iris_radius):\r\n",
    "                    for theta in samples:\r\n",
    "                        #get x and y for values on inner boundary\r\n",
    "                        x = (r+radius_pupil)*np.cos(theta)+center_x\r\n",
    "                        y = (r+radius_pupil)*np.sin(theta)+center_y\r\n",
    "                        x=int(x)\r\n",
    "                        y=int(y)\r\n",
    "                        try:\r\n",
    "                            #convert coordinates\r\n",
    "                            polar[r][int((theta*nsamples)/(2*np.pi))] = img[y][x]\r\n",
    "                        except IndexError: #ignores values which lie out of bounds\r\n",
    "                            pass\r\n",
    "                        continue\r\n",
    "                res = cv2.resize(polar,(512,64))\r\n",
    "                normalized.append(res)\r\n",
    "                cent+=1\r\n",
    "\r\n",
    "            h,w = normalized[0].shape # height, width\r\n",
    "\r\n",
    "            roi = normalized[0][10:h, 0:int(512/2)]\r\n",
    "            roi = roi.astype(np.uint8) \r\n",
    "            roi_enhanced = cv2.equalizeHist(roi)\r\n",
    "            cv2.imwrite(confi['general']['dataset_unif_segv2_edg_norm_dir'] + os.sep + file, roi_enhanced)\r\n",
    "\r\n",
    "            for i in centers:\r\n",
    "                x_pupil.append(i['pupil'][0])\r\n",
    "                y_pupil.append(i['pupil'][1])\r\n",
    "                r_pupil.append(i['pupil'][2])\r\n",
    "                x_iris.append(i['iris'][0])\r\n",
    "                y_iris.append(i['iris'][1])\r\n",
    "                r_iris.append(i['iris'][2])\r\n",
    "\r\n",
    "        data = {'image': image_files,\r\n",
    "        'pupil x_center':x_pupil,\r\n",
    "        'pupil y_center':y_pupil,\r\n",
    "        'pupil radius': r_pupil,\r\n",
    "        'iris x_center': x_iris,\r\n",
    "        'iris y_center': y_iris,\r\n",
    "        'iris radius':r_iris,\r\n",
    "        'class': classes}\r\n",
    "        \r\n",
    "        ################################# arrays must be the same lenght\r\n",
    "        df = pd.DataFrame(data)[['image','pupil x_center','pupil y_center','pupil radius','iris x_center', 'iris y_center','iris radius',\"class\"]] \r\n",
    "\r\n",
    "        df.to_csv(\"iris_data.csv\")\r\n",
    "    \r\n",
    "    else:\r\n",
    "        print(\"->Normalización realizada con anterioridad\")\r\n",
    "\r\n",
    "    return confi\r\n",
    "\r\n",
    "        "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Feature extraction"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## extraction()"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "def extraction(confi):\r\n",
    "    \r\n",
    "    print(\"Función 3.1, extraction()\")\r\n",
    "\r\n",
    "    ''' \r\n",
    "    Importando librerías\r\n",
    "    '''\r\n",
    "    try:\r\n",
    "        import os\r\n",
    "    except:\r\n",
    "        !pip install os\r\n",
    "        import os\r\n",
    "    try:\r\n",
    "        import cv2\r\n",
    "    except:\r\n",
    "        import cv2\r\n",
    "\r\n",
    "    from keras.applications.vgg16 import VGG16\r\n",
    "    from keras.applications.inception_v3 import InceptionV3\r\n",
    "    from keras.applications.resnet_v2 import ResNet50V2\r\n",
    "\r\n",
    "    from keras.applications.vgg16 import preprocess_input as vgg16_preprocessor\r\n",
    "    from keras.applications.inception_v3 import preprocess_input as inception_v3_preprocessor\r\n",
    "    from keras.applications.resnet_v2 import preprocess_input as resnet_v2_preprocessor\r\n",
    "\r\n",
    "\r\n",
    "    from keras.models import clone_model\r\n",
    "    from keras.models import Model\r\n",
    "    from keras.preprocessing import image\r\n",
    "\r\n",
    "\r\n",
    "    from IPython.display import clear_output\r\n",
    "    from tqdm import tqdm\r\n",
    "\r\n",
    "    import numpy as np\r\n",
    "\r\n",
    "    import matplotlib.pyplot as plt\r\n",
    "\r\n",
    "    import pandas as pd\r\n",
    "\r\n",
    "    \r\n",
    "    ''' \r\n",
    "    Estableciendo la root de la función\r\n",
    "    '''\r\n",
    "    os.chdir(confi['general']['root_dir'])\r\n",
    "    ''' \r\n",
    "    Creando funciones\r\n",
    "    '''\r\n",
    "    models_dict = {}\r\n",
    "    vgg16_dict, inception_v3_dict, resnet50_dict = {} ,{} ,{}\r\n",
    "\r\n",
    "    # if there a way to check if they are already load??\r\n",
    "    #\r\n",
    "    #\r\n",
    "    #\r\n",
    "    print(\"Loading VGG16\")\r\n",
    "    model = VGG16(weights='imagenet')\r\n",
    "    model = Model(model.input, model.layers[-2].output) # output_shape de la penúltima capa(fully-connected) -> (,4096)\r\n",
    "    vgg16_dict[\"model\"] = clone_model(model)\r\n",
    "    vgg16_dict[\"preprocesor\"] = vgg16_preprocessor\r\n",
    "    vgg16_dict[\"target_size\"] = model.input_shape[1], model.input_shape[2]# default vgg16 input (224,224)\r\n",
    "\r\n",
    "\r\n",
    "    print(\"Loading Inception v3\")\r\n",
    "    model = InceptionV3(weights='imagenet')\r\n",
    "    model = Model(model.input, model.layers[-2].output)# output_shape de la penúltima capa(pooling) -> (,2048)\r\n",
    "    inception_v3_dict[\"model\"] = clone_model(model)\r\n",
    "    inception_v3_dict[\"preprocesor\"] = inception_v3_preprocessor\r\n",
    "    inception_v3_dict[\"target_size\"] = model.input_shape[1],model.input_shape[2] # default inceptionv3 input (299,299)\r\n",
    "\r\n",
    "\r\n",
    "    print(\"Loading ResNet 50\")\r\n",
    "    model = ResNet50V2(weights='imagenet')\r\n",
    "    model = Model(model.input, model.layers[-2].output)# output_shape de la penúltima capa(pooling) -> (,2048)\r\n",
    "    resnet50_dict[\"model\"] = clone_model(model)\r\n",
    "    resnet50_dict[\"preprocesor\"] = resnet_v2_preprocessor\r\n",
    "    resnet50_dict[\"target_size\"] = model.input_shape[1],model.input_shape[2]# default ResNet input (224,224)\r\n",
    "\r\n",
    "\r\n",
    "    # diccionarios de los 3 modelos, clave -> nombre, valor -> otro diccionario\r\n",
    "    models_dict[\"VGG16\"] = vgg16_dict\r\n",
    "    models_dict[\"InceptionV3\"] = inception_v3_dict\r\n",
    "    models_dict[\"ResNet50\"] = resnet50_dict\r\n",
    "\r\n",
    "\r\n",
    "    confi['3.1_extraction']['models_dict'] = models_dict\r\n",
    "\r\n",
    "    clear_output()\r\n",
    "\r\n",
    "    ''' \r\n",
    "    Extract features: extracción de features pasandole una imágen y el modelo a utilizar\r\n",
    "    '''\r\n",
    "    def extract_features(image_path, model_name):\r\n",
    "        '''\r\n",
    "        model_name extaerá los features de la imagen que se le pase como parámetro.\r\n",
    "        '''\r\n",
    "        model_dict = models_dict[model_name]\r\n",
    "        ####\r\n",
    "        model = model_dict[\"model\"]\r\n",
    "        preprocessor = model_dict[\"preprocesor\"]\r\n",
    "        target_size = model_dict[\"target_size\"]\r\n",
    "        # se carga la imagen y después se ajusta al input shape del modelo\r\n",
    "        img = cv2.resize(cv2.imread(image_path),target_size)\r\n",
    "\r\n",
    "        img_data = image.img_to_array(img)\r\n",
    "        img_data = np.expand_dims(img_data, axis=0)\r\n",
    "        img_data = preprocessor(img_data)\r\n",
    "        \r\n",
    "        # extracción de features\r\n",
    "        features = model.predict(img_data)\r\n",
    "        return features[0]\r\n",
    "\r\n",
    "    def get_paths(directory):\r\n",
    "        '''\r\n",
    "        Devuelve la ruta relativa de las muestras .bmp\r\n",
    "        '''\r\n",
    "        paths = []\r\n",
    "        for root, dirs, files in os.walk(directory):\r\n",
    "            for file in files:\r\n",
    "                if file.endswith(\".bmp\"):\r\n",
    "                    paths.append(os.path.join(root, file))\r\n",
    "        return paths\r\n",
    "\r\n",
    "    # cargamos csv con los datos de las muestras\r\n",
    "    df = pd.read_csv(\"iris_data.csv\", dtype={'class': str}, index_col=0) # quitamos columna unnamed\r\n",
    "\r\n",
    "    # cambiamos nombre de columnas para evitar conflictos con palabras reservadas de Pytho\r\n",
    "    df.rename(columns={'image':'Image','class':'Clase'}, inplace=True)\r\n",
    "\r\n",
    "    def register_to_deepfeatures(register):\r\n",
    "        \"\"\"\r\n",
    "        Compute all CNN features    \r\n",
    "        \r\n",
    "        Parameters\r\n",
    "        ----------\r\n",
    "        register : Series\r\n",
    "            Serie containing metadata of the image\r\n",
    "    \r\n",
    "        Returns\r\n",
    "        -------\r\n",
    "        results : Series \r\n",
    "            A Pandas Serie contanining all of the features\r\n",
    "\r\n",
    "        \"\"\"\r\n",
    "        img_name = register.Image # nombre de la muestra e.g: Rafael_1.bmp\r\n",
    "        clase = register.Clase # clase e.g Rafael\r\n",
    "\r\n",
    "        img_dir = os.path.join(\"CASIA_IrisV1_unif_segv2_edg_norm\", img_name)\r\n",
    "\r\n",
    "        basic_values = pd.Series([img_name,clase],[\"Name\",\"Class\"])\r\n",
    "\r\n",
    "        all_features = []\r\n",
    "        all_names = []\r\n",
    "        models = models_dict.keys() # 3 modelos\r\n",
    "        \r\n",
    "        for model in models:\r\n",
    "            features = extract_features(img_dir, model)\r\n",
    "            names = [f\"{model}_{i}\" for i in range(len(features))]\r\n",
    "            all_features+=list(features)\r\n",
    "            all_names+= names\r\n",
    "            \r\n",
    "        results = pd.Series(all_features,all_names)\r\n",
    "        return pd.concat((basic_values,results))\r\n",
    "\r\n",
    "    # aplica la función a todas las FILAS del dataframe(parecido a map())\r\n",
    "    df_deep = df.apply(register_to_deepfeatures, axis=1)\r\n",
    "    df_deep.to_csv(\"iris_deep_features.csv\")\r\n",
    "\r\n",
    "    print(\"End extraction\")\r\n",
    "\r\n",
    "    return confi\r\n",
    "    "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## clasification()"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "def clasification(confi):\r\n",
    "    \r\n",
    "    print(\"Función 3.2, clasification()\")\r\n",
    "\r\n",
    "    ''' \r\n",
    "    Importando librerías\r\n",
    "    '''\r\n",
    "\r\n",
    "    try:\r\n",
    "        import cv2\r\n",
    "    except:\r\n",
    "        import cv2\r\n",
    "\r\n",
    "    import pickle\r\n",
    "\r\n",
    "    from sklearn.pipeline import make_pipeline\r\n",
    "    from sklearn.preprocessing import StandardScaler\r\n",
    "\r\n",
    "    from sklearn.model_selection import cross_val_score, cross_val_predict, GridSearchCV\r\n",
    "    from sklearn.pipeline import Pipeline\r\n",
    "\r\n",
    "    from sklearn.svm import LinearSVC, SVC # uno vs el resto\r\n",
    "    from sklearn.neighbors import KNeighborsClassifier\r\n",
    "    from sklearn.linear_model import LogisticRegression\r\n",
    "\r\n",
    "    from keras.preprocessing import image\r\n",
    "\r\n",
    "    # ensemble classifiers\r\n",
    "    from sklearn.ensemble import RandomForestClassifier\r\n",
    "    # from sklearn.ensemble import GradientBoostingClassifier\r\n",
    "\r\n",
    "    import winsound\r\n",
    "\r\n",
    "    import pandas as pd \r\n",
    "\r\n",
    "    import numpy as np\r\n",
    "\r\n",
    "    from sklearn.metrics import classification_report\r\n",
    "    from sklearn.metrics import accuracy_score\r\n",
    "    from sklearn.metrics import confusion_matrix\r\n",
    "\r\n",
    "    from sklearn.model_selection import train_test_split\r\n",
    "\r\n",
    "    from tqdm import tqdm\r\n",
    "\r\n",
    "    from joblib import dump, load\r\n",
    "\r\n",
    "    import heapq\r\n",
    "\r\n",
    "    import matplotlib.pyplot as plt\r\n",
    "\r\n",
    "    ''' \r\n",
    "    Elegir el estimador correcto\r\n",
    "    '''\r\n",
    "\r\n",
    "    data = pd.read_csv(\"iris_deep_features.csv\", dtype={'Class': str}, index_col=0)\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "    pretrained_models = [\"VGG16\",\"InceptionV3\",\"ResNet50\"]\r\n",
    "    # true labels\r\n",
    "    y = data.Class.values\r\n",
    "\r\n",
    "\r\n",
    "    vgg_cols = data.columns.str.startswith(\"VGG16\")\r\n",
    "    inception_cols = data.columns.str.startswith(\"InceptionV3\")\r\n",
    "    resnet_cols = data.columns.str.startswith(\"ResNet50\")\r\n",
    "\r\n",
    "\r\n",
    "    vgg_X = data[data.columns[vgg_cols]].values\r\n",
    "    inception_X = data[data.columns[inception_cols]].values\r\n",
    "    resnet_X = data[data.columns[resnet_cols]].values\r\n",
    "\r\n",
    "\r\n",
    "    datasets = [(vgg_X,y), (inception_X,y), (resnet_X,y)]\r\n",
    "    datasets_names = pretrained_models.copy()\r\n",
    "\r\n",
    "    '''\r\n",
    "    List of classifiers and their names included in the experimental study\r\n",
    "    '''\r\n",
    "\r\n",
    "    cls_names = [\"SVM\", \"Nearest Neighbors\", \"LogisticRegression\", \"Random Forest\"] #\"Gradient Boosting Trees\"]\r\n",
    "\r\n",
    "    classifiers = [ make_pipeline(StandardScaler(), SVC(kernel='linear')), #(StandardScaler(), grid_svm)\r\n",
    "                    make_pipeline(StandardScaler(), KNeighborsClassifier(3)),\r\n",
    "                    make_pipeline(StandardScaler(), LogisticRegression(max_iter=1000)),\r\n",
    "                    RandomForestClassifier(random_state=0, n_estimators=100),\r\n",
    "    #                 GradientBoostingClassifier(random_state=0, n_estimators=100)\r\n",
    "                    ]\r\n",
    "\r\n",
    "\r\n",
    "    def cross_validate_preds_model(X, y, model, num_folds):\r\n",
    "        '''\r\n",
    "        @author José F. Díez Pastor\r\n",
    "        Perform cross validation with a model and a dataset (X and y),\r\n",
    "        and returns the predictions to later obtain the measurements \r\n",
    "        you want\r\n",
    "        \r\n",
    "        Parameters\r\n",
    "        ----------\r\n",
    "        X: numpy.array\r\n",
    "            Dataset (features)\r\n",
    "        Y: numpy.array\r\n",
    "            Dataset (Target)\r\n",
    "        model: scikit_model\r\n",
    "            model to be trained\r\n",
    "        num_folds: int\r\n",
    "            number of folds in the cross validation\r\n",
    "        \r\n",
    "        Return\r\n",
    "        -------\r\n",
    "        array \r\n",
    "            array of prediccions obtained using cross_validation\r\n",
    "        '''\r\n",
    "        print('\\t'+str(model)[:20]+\"...\", end=' - ')\r\n",
    "        preds = cross_val_predict(model,X,y,cv=num_folds)\r\n",
    "        print('OK')\r\n",
    "        \r\n",
    "        return preds\r\n",
    "\r\n",
    "    def run_all_save(num_folds,filename):\r\n",
    "        '''\r\n",
    "        @author José F. Díez Pastor\r\n",
    "        Perform cross validation with all models and datasets.\r\n",
    "            \r\n",
    "            \r\n",
    "        Parameters\r\n",
    "        ----------\r\n",
    "        num_folds: int\r\n",
    "            number of folds in the cross validation\r\n",
    "        filename: string\r\n",
    "            name of the file that stores the predictions obtained using crossvalidation\r\n",
    "            \r\n",
    "        Return\r\n",
    "        -------\r\n",
    "        \r\n",
    "        ''' \r\n",
    "        \r\n",
    "        all_preds = {}\r\n",
    "\r\n",
    "        for dataset,dataset_name in tqdm(zip(datasets, datasets_names)):\r\n",
    "            print(f\"----------Pre-trained network: {dataset_name}-----------\")\r\n",
    "            X,y = dataset\r\n",
    "            for model,cls_name in zip(classifiers,cls_names):\r\n",
    "                print(f\"-> {cls_name}\")\r\n",
    "                preds = cross_validate_preds_model(X, y, model, num_folds)\r\n",
    "                all_preds[(dataset_name,cls_name)]=(y,preds)\r\n",
    "\r\n",
    "        all_preds[\"cls_names\"]=cls_names\r\n",
    "        all_preds[\"dataset_names\"]=datasets_names\r\n",
    "\r\n",
    "        with open(filename, 'wb') as fp:\r\n",
    "            pickle.dump(all_preds, fp)\r\n",
    "    \r\n",
    "        ''' \r\n",
    "    Extract features: extracción de features pasandole una imágen y el modelo a utilizar\r\n",
    "    '''\r\n",
    "    def extract_features(image_path, model_name):\r\n",
    "        '''\r\n",
    "        model_name extaerá los features de la imagen que se le pase como parámetro.\r\n",
    "        '''\r\n",
    "        model_dict = confi['3.1_extraction']['models_dict'][model_name]\r\n",
    "        ####\r\n",
    "        model = model_dict[\"model\"]\r\n",
    "        preprocessor = model_dict[\"preprocesor\"]\r\n",
    "        target_size = model_dict[\"target_size\"]\r\n",
    "        # se carga la imagen y después se ajusta al input shape del modelo\r\n",
    "        img = cv2.resize(cv2.imread(image_path),target_size)\r\n",
    "\r\n",
    "        img_data = image.img_to_array(img)\r\n",
    "        img_data = np.expand_dims(img_data, axis=0)\r\n",
    "        img_data = preprocessor(img_data)\r\n",
    "        \r\n",
    "        # extracción de features\r\n",
    "        features = model.predict(img_data)\r\n",
    "        return features[0]\r\n",
    "\r\n",
    "    \r\n",
    "    freq = 1500\r\n",
    "    dur = 1000\r\n",
    "\r\n",
    "    obj_file = \"evaluation_models.obj\"\r\n",
    "\r\n",
    "    run_all_save(4,obj_file) # 4 folds (divisor de 756)\r\n",
    "    winsound.Beep(freq,dur)\r\n",
    "\r\n",
    "    def get_results(filename):\r\n",
    "        '''\r\n",
    "        @author: José F. Diez Pastor\r\n",
    "        Load the file with the predictions.\r\n",
    "        Compute accuracy, confusion matrix and other measures.\r\n",
    "            \r\n",
    "            \r\n",
    "        Parameters\r\n",
    "        ----------\r\n",
    "        filename: string\r\n",
    "            name of the file that stores the predictions obtained using crossvalidation\r\n",
    "            \r\n",
    "        Return\r\n",
    "        dictionary\r\n",
    "            A dictionary of key:values that asociates the name\r\n",
    "            of a measure or chart with the value\r\n",
    "        -------\r\n",
    "        \r\n",
    "        ''' \r\n",
    "\r\n",
    "        with open(filename, 'rb') as fp:\r\n",
    "            all_preds = pickle.load(fp)\r\n",
    "\r\n",
    "        cls_names = all_preds.pop(\"cls_names\")\r\n",
    "        dataset_names = all_preds.pop(\"dataset_names\")\r\n",
    "\r\n",
    "        data_cls_pairs = list(all_preds.keys())\r\n",
    "        data_cls_pairs.sort()\r\n",
    "\r\n",
    "        results = {}\r\n",
    "\r\n",
    "\r\n",
    "        acc_df = pd.DataFrame(index=dataset_names, columns=cls_names)\r\n",
    "\r\n",
    "        ## A DataFrame is created to store the accuracy in each clase\r\n",
    "        for dataset in dataset_names:\r\n",
    "            results[(dataset,\"acc\")] = pd.DataFrame(columns=cls_names)\r\n",
    "\r\n",
    "\r\n",
    "        for dataset_name,cls_name in tqdm(data_cls_pairs):\r\n",
    "            #print(dataset_name,cls_name)\r\n",
    "            y_true, y_pred = all_preds[(dataset_name,cls_name)]\r\n",
    "            labels = list(np.unique(y_true))\r\n",
    "\r\n",
    "            acc = accuracy_score(y_true, y_pred)\r\n",
    "            # Fill accuracy dataframe\r\n",
    "            acc_df.at[dataset_name,cls_name]=acc\r\n",
    "            \r\n",
    "            report = classification_report(y_true, y_pred, output_dict=True)\r\n",
    "            report_df = pd.DataFrame(report).transpose()\r\n",
    "            results[(dataset_name,cls_name,\"report\")] = report_df\r\n",
    "\r\n",
    "        results[\"Acc\"] = acc_df\r\n",
    "        return results\r\n",
    "\r\n",
    "\r\n",
    "    results = get_results(obj_file)\r\n",
    "\r\n",
    "    precisions = {}\r\n",
    "    for i in results.keys():\r\n",
    "        if i[-1] == \"report\":\r\n",
    "            print(i,end=\" -> \")\r\n",
    "            print(results[i][\"precision\"][-3])\r\n",
    "            precisions[results[i][\"precision\"][-3]] = i\r\n",
    "    highest_precision = precisions[max(precisions)]\r\n",
    "    highest_precision\r\n",
    "\r\n",
    "    best_model = highest_precision[0]\r\n",
    "    best_classifier = highest_precision[1]\r\n",
    "    print(f\"Best Precision: \\n\\t - Model: {best_model}\\n\\t - Classifier: {best_classifier}\")\r\n",
    "\r\n",
    "    print(\"Step 2\")\r\n",
    "\r\n",
    "    X, y = datasets[1] #datasets = [(vgg_X,y), (inception_X,y), (resnet_X,y)]\r\n",
    "\r\n",
    "    # Dividimos los datos en entranamiento (80%) y testeo dejando (20%)\r\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\r\n",
    "    clf = classifiers[2] # LogisticRegression\r\n",
    "\r\n",
    "    clf.fit(X_train,y_train)\r\n",
    "\r\n",
    "    clf.score(X_test, y_test)\r\n",
    "\r\n",
    "    # guardamos el modelo\r\n",
    "    dump(clf, \"logistic_clf_trained.pkl\")\r\n",
    "\r\n",
    "    print(\"Step 3\")\r\n",
    "\r\n",
    "    ''' \r\n",
    "    Última etapa del reconocimiento: Matching\r\n",
    "    '''\r\n",
    "    ### Reconocer un sujeto (CASIA_IrisV1_unif_segv2_edg_norm)\r\n",
    "    img = r'CASIA_IrisV1_unif_segv2_edg_norm\\001_1_1.bmp' # cambiar ruta a directorio CASIA_IrisV1_unif_segv2_edg_norm\r\n",
    "    test_sample = extract_features(img, \"InceptionV3\")\r\n",
    "\r\n",
    "    # cambiamos el shape para que los transforme a una fila\r\n",
    "    test_sample.shape = [1,2048]\r\n",
    "\r\n",
    "    prediction = clf.predict(test_sample)\r\n",
    "\r\n",
    "    prediction_prob = clf.predict_proba(test_sample)\r\n",
    "\r\n",
    "    labels = np.unique(y) # 108 individuos\r\n",
    "\r\n",
    "    #juntamos individuos y la probabilidades\r\n",
    "    predicted_dict = dict(zip(prediction_prob[0], labels))\r\n",
    "\r\n",
    "    print(predicted_dict)\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "    # 5 individuos más probables \r\n",
    "    top_five = heapq.nlargest(5, predicted_dict)\r\n",
    "    labels, probs = [], []\r\n",
    "    for k,v in predicted_dict.items():\r\n",
    "        if k in top_five:\r\n",
    "            print(v+\" -> \"+str(k)+\"%\")\r\n",
    "            labels.append(v)\r\n",
    "            probs.append(k)\r\n",
    "\r\n",
    "    y_pos = np.arange(len(labels))\r\n",
    "    fig = plt.figure(figsize = (10,5))\r\n",
    "    plt.bar(labels, [i*100 for i in probs], color = 'green', width = 0.6)\r\n",
    "\r\n",
    "    plt.xticks(y_pos, labels)\r\n",
    "    plt.ylabel('Prediction %')\r\n",
    "    plt.title('Iris Prediction...')\r\n",
    "\r\n",
    "    plt.show()\r\n",
    "\r\n",
    "    modelo_cargado = load(\"logistic_clf_trained.pkl\")\r\n",
    "    test_sample = extract_features(r\"CASIA_IrisV1_unif_segv2_edg_norm\\002_1_1.bmp\", \"InceptionV3\")\r\n",
    "    test_sample.shape = [1,test_sample.shape[0]]\r\n",
    "    modelo_cargado.predict(test_sample)\r\n",
    "\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "def clasification(confi):\r\n",
    "    \r\n",
    "    print(\"Función 3.2, clasification()\")\r\n",
    "\r\n",
    "    ''' \r\n",
    "    Importando librerías\r\n",
    "    '''\r\n",
    "\r\n",
    "    try:\r\n",
    "        import cv2\r\n",
    "    except:\r\n",
    "        import cv2\r\n",
    "\r\n",
    "    import pickle\r\n",
    "\r\n",
    "    from sklearn.pipeline import make_pipeline\r\n",
    "    from sklearn.preprocessing import StandardScaler\r\n",
    "\r\n",
    "    from sklearn.model_selection import cross_val_score, cross_val_predict, GridSearchCV\r\n",
    "    from sklearn.pipeline import Pipeline\r\n",
    "\r\n",
    "    from sklearn.svm import LinearSVC, SVC # uno vs el resto\r\n",
    "    from sklearn.neighbors import KNeighborsClassifier\r\n",
    "    from sklearn.linear_model import LogisticRegression\r\n",
    "\r\n",
    "    from keras.preprocessing import image\r\n",
    "\r\n",
    "    # ensemble classifiers\r\n",
    "    from sklearn.ensemble import RandomForestClassifier\r\n",
    "    # from sklearn.ensemble import GradientBoostingClassifier\r\n",
    "\r\n",
    "    import winsound\r\n",
    "\r\n",
    "    import pandas as pd \r\n",
    "\r\n",
    "    import numpy as np\r\n",
    "\r\n",
    "    from sklearn.metrics import classification_report\r\n",
    "    from sklearn.metrics import accuracy_score\r\n",
    "    from sklearn.metrics import confusion_matrix\r\n",
    "\r\n",
    "    from sklearn.model_selection import train_test_split\r\n",
    "\r\n",
    "    from tqdm import tqdm\r\n",
    "\r\n",
    "    from joblib import dump, load\r\n",
    "\r\n",
    "    import heapq\r\n",
    "\r\n",
    "    import matplotlib.pyplot as plt\r\n",
    "\r\n",
    "    ''' \r\n",
    "    Elegir el estimador correcto\r\n",
    "    '''\r\n",
    "\r\n",
    "    data = pd.read_csv(\"iris_deep_features.csv\", dtype={'Class': str}, index_col=0)\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "    pretrained_models = [\"VGG16\",\"InceptionV3\",\"ResNet50\"]\r\n",
    "    # true labels\r\n",
    "    y = data.Class.values\r\n",
    "\r\n",
    "\r\n",
    "    vgg_cols = data.columns.str.startswith(\"VGG16\")\r\n",
    "    inception_cols = data.columns.str.startswith(\"InceptionV3\")\r\n",
    "    resnet_cols = data.columns.str.startswith(\"ResNet50\")\r\n",
    "\r\n",
    "\r\n",
    "    vgg_X = data[data.columns[vgg_cols]].values\r\n",
    "    inception_X = data[data.columns[inception_cols]].values\r\n",
    "    resnet_X = data[data.columns[resnet_cols]].values\r\n",
    "\r\n",
    "\r\n",
    "    datasets = [(vgg_X,y), (inception_X,y), (resnet_X,y)]\r\n",
    "    datasets_names = pretrained_models.copy()\r\n",
    "\r\n",
    "    '''\r\n",
    "    List of classifiers and their names included in the experimental study\r\n",
    "    '''\r\n",
    "\r\n",
    "    cls_names = [\"SVM\", \"Nearest Neighbors\", \"LogisticRegression\", \"Random Forest\"] #\"Gradient Boosting Trees\"]\r\n",
    "\r\n",
    "    classifiers = [ make_pipeline(StandardScaler(), SVC(kernel='linear')), #(StandardScaler(), grid_svm)\r\n",
    "                    make_pipeline(StandardScaler(), KNeighborsClassifier(3)),\r\n",
    "                    make_pipeline(StandardScaler(), LogisticRegression(max_iter=1000)),\r\n",
    "                    RandomForestClassifier(random_state=0, n_estimators=100),\r\n",
    "    #                 GradientBoostingClassifier(random_state=0, n_estimators=100)\r\n",
    "                    ]\r\n",
    "\r\n",
    "\r\n",
    "    def cross_validate_preds_model(X, y, model, num_folds):\r\n",
    "        '''\r\n",
    "        @author José F. Díez Pastor\r\n",
    "        Perform cross validation with a model and a dataset (X and y),\r\n",
    "        and returns the predictions to later obtain the measurements \r\n",
    "        you want\r\n",
    "        \r\n",
    "        Parameters\r\n",
    "        ----------\r\n",
    "        X: numpy.array\r\n",
    "            Dataset (features)\r\n",
    "        Y: numpy.array\r\n",
    "            Dataset (Target)\r\n",
    "        model: scikit_model\r\n",
    "            model to be trained\r\n",
    "        num_folds: int\r\n",
    "            number of folds in the cross validation\r\n",
    "        \r\n",
    "        Return\r\n",
    "        -------\r\n",
    "        array \r\n",
    "            array of prediccions obtained using cross_validation\r\n",
    "        '''\r\n",
    "        print('\\t'+str(model)[:20]+\"...\", end=' - ')\r\n",
    "        preds = cross_val_predict(model,X,y,cv=num_folds)\r\n",
    "        print('OK')\r\n",
    "        \r\n",
    "        return preds\r\n",
    "\r\n",
    "    def run_all_save(num_folds,filename):\r\n",
    "        '''\r\n",
    "        @author José F. Díez Pastor\r\n",
    "        Perform cross validation with all models and datasets.\r\n",
    "            \r\n",
    "            \r\n",
    "        Parameters\r\n",
    "        ----------\r\n",
    "        num_folds: int\r\n",
    "            number of folds in the cross validation\r\n",
    "        filename: string\r\n",
    "            name of the file that stores the predictions obtained using crossvalidation\r\n",
    "            \r\n",
    "        Return\r\n",
    "        -------\r\n",
    "        \r\n",
    "        ''' \r\n",
    "        \r\n",
    "        all_preds = {}\r\n",
    "\r\n",
    "        for dataset,dataset_name in tqdm(zip(datasets, datasets_names)):\r\n",
    "            print(f\"----------Pre-trained network: {dataset_name}-----------\")\r\n",
    "            X,y = dataset\r\n",
    "            for model,cls_name in zip(classifiers,cls_names):\r\n",
    "                print(f\"-> {cls_name}\")\r\n",
    "                preds = cross_validate_preds_model(X, y, model, num_folds)\r\n",
    "                all_preds[(dataset_name,cls_name)]=(y,preds)\r\n",
    "\r\n",
    "        all_preds[\"cls_names\"]=cls_names\r\n",
    "        all_preds[\"dataset_names\"]=datasets_names\r\n",
    "\r\n",
    "        with open(filename, 'wb') as fp:\r\n",
    "            pickle.dump(all_preds, fp)\r\n",
    "    \r\n",
    "        ''' \r\n",
    "    Extract features: extracción de features pasandole una imágen y el modelo a utilizar\r\n",
    "    '''\r\n",
    "    def extract_features(image_path, model_name):\r\n",
    "        '''\r\n",
    "        model_name extaerá los features de la imagen que se le pase como parámetro.\r\n",
    "        '''\r\n",
    "        model_dict = confi['3.1_extraction']['models_dict'][model_name]\r\n",
    "        ####\r\n",
    "        model = model_dict[\"model\"]\r\n",
    "        preprocessor = model_dict[\"preprocesor\"]\r\n",
    "        target_size = model_dict[\"target_size\"]\r\n",
    "        # se carga la imagen y después se ajusta al input shape del modelo\r\n",
    "        img = cv2.resize(cv2.imread(image_path),target_size)\r\n",
    "\r\n",
    "        img_data = image.img_to_array(img)\r\n",
    "        img_data = np.expand_dims(img_data, axis=0)\r\n",
    "        img_data = preprocessor(img_data)\r\n",
    "        \r\n",
    "        # extracción de features\r\n",
    "        features = model.predict(img_data)\r\n",
    "        return features[0]\r\n",
    "\r\n",
    "    \r\n",
    "    freq = 1500\r\n",
    "    dur = 1000\r\n",
    "\r\n",
    "    obj_file = \"evaluation_models.obj\"\r\n",
    "\r\n",
    "    run_all_save(4,obj_file) # 4 folds (divisor de 756)\r\n",
    "    winsound.Beep(freq,dur)\r\n",
    "\r\n",
    "    def get_results(filename):\r\n",
    "        '''\r\n",
    "        @author: José F. Diez Pastor\r\n",
    "        Load the file with the predictions.\r\n",
    "        Compute accuracy, confusion matrix and other measures.\r\n",
    "            \r\n",
    "            \r\n",
    "        Parameters\r\n",
    "        ----------\r\n",
    "        filename: string\r\n",
    "            name of the file that stores the predictions obtained using crossvalidation\r\n",
    "            \r\n",
    "        Return\r\n",
    "        dictionary\r\n",
    "            A dictionary of key:values that asociates the name\r\n",
    "            of a measure or chart with the value\r\n",
    "        -------\r\n",
    "        \r\n",
    "        ''' \r\n",
    "\r\n",
    "        with open(filename, 'rb') as fp:\r\n",
    "            all_preds = pickle.load(fp)\r\n",
    "\r\n",
    "        cls_names = all_preds.pop(\"cls_names\")\r\n",
    "        dataset_names = all_preds.pop(\"dataset_names\")\r\n",
    "\r\n",
    "        data_cls_pairs = list(all_preds.keys())\r\n",
    "        data_cls_pairs.sort()\r\n",
    "\r\n",
    "        results = {}\r\n",
    "\r\n",
    "\r\n",
    "        acc_df = pd.DataFrame(index=dataset_names, columns=cls_names)\r\n",
    "\r\n",
    "        ## A DataFrame is created to store the accuracy in each clase\r\n",
    "        for dataset in dataset_names:\r\n",
    "            results[(dataset,\"acc\")] = pd.DataFrame(columns=cls_names)\r\n",
    "\r\n",
    "\r\n",
    "        for dataset_name,cls_name in tqdm(data_cls_pairs):\r\n",
    "            #print(dataset_name,cls_name)\r\n",
    "            y_true, y_pred = all_preds[(dataset_name,cls_name)]\r\n",
    "            labels = list(np.unique(y_true))\r\n",
    "\r\n",
    "            acc = accuracy_score(y_true, y_pred)\r\n",
    "            # Fill accuracy dataframe\r\n",
    "            acc_df.at[dataset_name,cls_name]=acc\r\n",
    "            \r\n",
    "            report = classification_report(y_true, y_pred, output_dict=True)\r\n",
    "            report_df = pd.DataFrame(report).transpose()\r\n",
    "            results[(dataset_name,cls_name,\"report\")] = report_df\r\n",
    "\r\n",
    "        results[\"Acc\"] = acc_df\r\n",
    "        return results\r\n",
    "\r\n",
    "\r\n",
    "    results = get_results(obj_file)\r\n",
    "\r\n",
    "    precisions = {}\r\n",
    "    for i in results.keys():\r\n",
    "        if i[-1] == \"report\":\r\n",
    "            print(i,end=\" -> \")\r\n",
    "            print(results[i][\"precision\"][-3])\r\n",
    "            precisions[results[i][\"precision\"][-3]] = i\r\n",
    "    highest_precision = precisions[max(precisions)]\r\n",
    "    highest_precision\r\n",
    "\r\n",
    "    best_model = highest_precision[0]\r\n",
    "    best_classifier = highest_precision[1]\r\n",
    "    print(f\"Best Precision: \\n\\t - Model: {best_model}\\n\\t - Classifier: {best_classifier}\")\r\n",
    "\r\n",
    "    X, y = datasets[1] #datasets = [(vgg_X,y), (inception_X,y), (resnet_X,y)]\r\n",
    "\r\n",
    "    # Dividimos los datos en entranamiento (80%) y testeo dejando (20%)\r\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\r\n",
    "    clf = classifiers[2] # LogisticRegression\r\n",
    "\r\n",
    "    clf.fit(X_train,y_train)\r\n",
    "\r\n",
    "    clf.score(X_test, y_test)\r\n",
    "\r\n",
    "    # guardamos el modelo\r\n",
    "    dump(clf, \"logistic_clf_trained.pkl\")\r\n",
    "\r\n",
    "    print(confi['3.1_extraction'])\r\n",
    "\r\n",
    "    ''' \r\n",
    "    Última etapa del reconocimiento: Matching\r\n",
    "    '''\r\n",
    "    ### Reconocer un sujeto (CASIA_IrisV1_unif_segv2_edg_norm)\r\n",
    "    img = r'CASIA_IrisV1_unif_segv2_edg_norm\\001_1_1.bmp' # cambiar ruta a directorio CASIA_IrisV1_unif_segv2_edg_norm\r\n",
    "    test_sample = extract_features(img, \"InceptionV3\")\r\n",
    "\r\n",
    "    # cambiamos el shape para que los transforme a una fila\r\n",
    "    test_sample.shape = [1,2048]\r\n",
    "\r\n",
    "    prediction = clf.predict(test_sample)\r\n",
    "\r\n",
    "    prediction_prob = clf.predict_proba(test_sample)\r\n",
    "\r\n",
    "    labels = np.unique(y) # 108 individuos\r\n",
    "\r\n",
    "    #juntamos individuos y la probabilidades\r\n",
    "    predicted_dict = dict(zip(prediction_prob[0], labels))\r\n",
    "\r\n",
    "    print(predicted_dict)\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "    # 5 individuos más probables \r\n",
    "    top_five = heapq.nlargest(5, predicted_dict)\r\n",
    "    labels, probs = [], []\r\n",
    "    for k,v in predicted_dict.items():\r\n",
    "        if k in top_five:\r\n",
    "            print(v+\" -> \"+str(k)+\"%\")\r\n",
    "            labels.append(v)\r\n",
    "            probs.append(k)\r\n",
    "\r\n",
    "    y_pos = np.arange(len(labels))\r\n",
    "    fig = plt.figure(figsize = (10,5))\r\n",
    "    plt.bar(labels, [i*100 for i in probs], color = 'green', width = 0.6)\r\n",
    "\r\n",
    "    plt.xticks(y_pos, labels)\r\n",
    "    plt.ylabel('Prediction %')\r\n",
    "    plt.title('Iris Prediction...')\r\n",
    "\r\n",
    "    plt.show()\r\n",
    "\r\n",
    "    modelo_cargado = load(\"logistic_clf_trained.pkl\")\r\n",
    "    test_sample = extract_features(r\"CASIA_IrisV1_unif_segv2_edg_norm\\002_1_1.bmp\", \"InceptionV3\")\r\n",
    "    test_sample.shape = [1,test_sample.shape[0]]\r\n",
    "    modelo_cargado.predict(test_sample)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Definir y ejecutar el pipeline"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Definición del pipeline"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "try:\r\n",
    "    from sklearn.preprocessing import FunctionTransformer\r\n",
    "    from sklearn.pipeline import Pipeline\r\n",
    "except ImportError as e:\r\n",
    "    !pip install sklearn\r\n",
    "    from sklearn.preprocessing import FunctionTransformer\r\n",
    "    from sklearn.pipeline import Pipeline"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "_1_tratar_dataset_pip = FunctionTransformer(tratar_dataset_casia)\r\n",
    "_1_1_data_augmentation_pip = FunctionTransformer(data_augmentation)\r\n",
    "_2_1_segmentation_pip = FunctionTransformer(segmentation)\r\n",
    "_2_2_normalization_pip = FunctionTransformer(normalization)\r\n",
    "_3_1_extraction_pip = FunctionTransformer(extraction)\r\n",
    "_3_2_clasification_pip = FunctionTransformer(clasification)\r\n",
    "\r\n",
    "iris_recognition_pipeline = Pipeline([('_1_tratarDataset', _1_tratar_dataset_pip), \r\n",
    "                                    ('_1_1_dataAugmentation', _1_1_data_augmentation_pip), \r\n",
    "                                    ('_2_1_segmentation', _2_1_segmentation_pip), \r\n",
    "                                    ('_2_2_normalization', _2_2_normalization_pip),\r\n",
    "                                    ('_3_1_extraction', _3_1_extraction_pip),\r\n",
    "                                    ('_3_2_clasification', _3_2_clasification_pip)])\r\n",
    "\r\n",
    "# iris_recognition_pipeline = Pipeline([('_1_tratarDataset', _1_tratar_dataset_pip), \r\n",
    "#                                     ('_2_1_segmentation', _2_1_segmentation_pip), \r\n",
    "#                                     ('_2_2_mormalization', _2_2_normalization_pip)])\r\n",
    "\r\n",
    "# iris_recognition_pipeline = Pipeline([('_2_2_mormalization', _2_2_normalization_pip)])\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Ejecición pipeline\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "iris_recognition_pipeline.transform(confi_dict)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "End extraction\n",
      "Función 3.2, clasification()\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "----------Pre-trained network: VGG16-----------\n",
      "-> SVM\n",
      "\tPipeline(steps=[('st... - OK\n",
      "-> Nearest Neighbors\n",
      "\tPipeline(steps=[('st... - OK\n",
      "-> LogisticRegression\n",
      "\tPipeline(steps=[('st... - OK\n",
      "-> Random Forest\n",
      "\tRandomForestClassifi... - "
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "1it [00:00,  1.67it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "OK\n",
      "----------Pre-trained network: InceptionV3-----------\n",
      "-> SVM\n",
      "\tPipeline(steps=[('st... - OK\n",
      "-> Nearest Neighbors\n",
      "\tPipeline(steps=[('st... - OK\n",
      "-> LogisticRegression\n",
      "\tPipeline(steps=[('st... - OK\n",
      "-> Random Forest\n",
      "\tRandomForestClassifi... - "
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2it [00:01,  1.70it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "OK\n",
      "----------Pre-trained network: ResNet50-----------\n",
      "-> SVM\n",
      "\tPipeline(steps=[('st... - OK\n",
      "-> Nearest Neighbors\n",
      "\tPipeline(steps=[('st... - OK\n",
      "-> LogisticRegression\n",
      "\tPipeline(steps=[('st... - OK\n",
      "-> Random Forest\n",
      "\tRandomForestClassifi... - "
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "3it [00:01,  1.76it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "OK\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n",
      "100%|██████████| 12/12 [00:00<00:00, 139.91it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "('InceptionV3', 'LogisticRegression', 'report') -> 1.0\n",
      "('InceptionV3', 'Nearest Neighbors', 'report') -> 1.0\n",
      "('InceptionV3', 'Random Forest', 'report') -> 0.9285714285714286\n",
      "('InceptionV3', 'SVM', 'report') -> 1.0\n",
      "('ResNet50', 'LogisticRegression', 'report') -> 1.0\n",
      "('ResNet50', 'Nearest Neighbors', 'report') -> 1.0\n",
      "('ResNet50', 'Random Forest', 'report') -> 1.0\n",
      "('ResNet50', 'SVM', 'report') -> 1.0\n",
      "('VGG16', 'LogisticRegression', 'report') -> 1.0\n",
      "('VGG16', 'Nearest Neighbors', 'report') -> 1.0\n",
      "('VGG16', 'Random Forest', 'report') -> 1.0\n",
      "('VGG16', 'SVM', 'report') -> 1.0\n",
      "Best Precision: \n",
      "\t - Model: VGG16\n",
      "\t - Classifier: SVM\n",
      "{'models_dict': {'VGG16': {'model': <keras.engine.functional.Functional object at 0x0000015FA763CCC0>, 'preprocesor': <function preprocess_input at 0x0000015F9F359400>, 'target_size': (224, 224)}, 'InceptionV3': {'model': <keras.engine.functional.Functional object at 0x0000015FA89CBE48>, 'preprocesor': <function preprocess_input at 0x0000015F9F3329D8>, 'target_size': (299, 299)}, 'ResNet50': {'model': <keras.engine.functional.Functional object at 0x0000015FA8252550>, 'preprocesor': <function preprocess_input at 0x0000015F9F359158>, 'target_size': (224, 224)}}}\n",
      "{0.9995796798331623: '001', 0.0004203201668376549: '002'}\n",
      "001 -> 0.9995796798331623%\n",
      "002 -> 0.0004203201668376549%\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.0",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.0 64-bit (system)"
  },
  "interpreter": {
   "hash": "0600588c3b5f4418cbe7b5ebc6825b479f3bc010269d8b60d75058cdd010adfe"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}